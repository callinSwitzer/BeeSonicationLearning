{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callin Switzer\n",
    "### 16 March 2018\n",
    "### Classify Sequential data using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import seaborn as sns\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "from scipy import signal\n",
    "import itertools as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "import graphviz as gv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Dropbox\\SonicationBehavior\\SonBehData\n"
     ]
    }
   ],
   "source": [
    "def windowsOrMacDirectories():\n",
    "    \"\"\" Sets base directories for win or mac\n",
    "\n",
    "       \n",
    "    \"\"\"\n",
    "    if os.environ['COMPUTERNAME'] == 'SHEALMACLEARN':\n",
    "        DropboxDirect = os.path.join(\"D:\\Dropbox\")\n",
    "#     elif sys.platform.startswith('linux') or sys.platform.startswith('cygwin'):\n",
    "#         # this excludes your current terminal \"/dev/tty\"\n",
    "    elif sys.platform.startswith('darwin'):\n",
    "        DropboxDirect = os.path.join(\"/Users/cswitzer/Dropbox\")\n",
    "    else:\n",
    "        raise EnvironmentError('Unknown computer platform')\n",
    "    \n",
    "    baseDir = os.getcwd()\n",
    "    dataDir = os.path.join(DropboxDirect, 'SonicationBehavior', 'SonBehData')\n",
    "    figDir = os.path.join(DropboxDirect, 'SonicationBehavior', 'SonBehFigs')\n",
    "    return baseDir, dataDir, figDir\n",
    "\n",
    "\n",
    "baseDir, dataDir, figDir = windowsOrMacDirectories()\n",
    "print(dataDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Practice \n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\calli\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7157 - acc: 0.5080\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.7100 - acc: 0.5080\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.7048 - acc: 0.5210\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.7040 - acc: 0.4970\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.7125 - acc: 0.4940\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.7046 - acc: 0.5090\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.6966 - acc: 0.5180\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.7016 - acc: 0.5030\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.6938 - acc: 0.5260\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.6988 - acc: 0.4920\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.6921 - acc: 0.5380\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.6975 - acc: 0.5060\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.6885 - acc: 0.5340\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.6974 - acc: 0.5080\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.6941 - acc: 0.5230\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.6918 - acc: 0.5400\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.6929 - acc: 0.5160\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.6929 - acc: 0.5290\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.6947 - acc: 0.5120\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.6881 - acc: 0.5360\n",
      "100/100 [==============================] - 0s 230us/step\n"
     ]
    }
   ],
   "source": [
    "# Generate dummy data\n",
    "x_train = np.random.random((1000, 20))\n",
    "y_train = np.random.randint(2, size=(1000, 1))\n",
    "x_test = np.random.random((100, 20))\n",
    "y_test = np.random.randint(2, size=(100, 1))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=20, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128)\n",
    "score = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\calli\\Anaconda3\\envs\\deeplearning\\Library\\bin;C:\\Users\\calli\\Anaconda3;C:\\Users\\calli\\Anaconda3\\Library\\mingw-w64\\bin;C:\\Users\\calli\\Anaconda3\\Library\\usr\\bin;C:\\Users\\calli\\Anaconda3\\Library\\bin;C:\\Users\\calli\\Anaconda3\\Scripts;C:\\Users\\calli\\Anaconda3\\bin;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\bin;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\libnvvp;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\;C:\\Program Files\\Git\\cmd;C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common;C:\\Program Files (x86)\\Graphviz2.38\\bin;C:\\Users\\calli\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Program Files\\Microsoft VS Code\\bin;;C:\\Users\\calli\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\numpy\\.libs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.environ['Path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "from keras.utils import plot_model\n",
    "import pydot\n",
    "plot_model(model, to_file=os.path.join(figDir,'modelTest.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 11.5361 - acc: 0.1040 - val_loss: 11.6593 - val_acc: 0.0500\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 308us/step - loss: 11.5342 - acc: 0.0800 - val_loss: 11.6575 - val_acc: 0.0700\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 309us/step - loss: 11.5330 - acc: 0.0970 - val_loss: 11.6565 - val_acc: 0.0800\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 312us/step - loss: 11.5316 - acc: 0.1130 - val_loss: 11.6557 - val_acc: 0.1100\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 305us/step - loss: 11.5313 - acc: 0.0920 - val_loss: 11.6588 - val_acc: 0.0800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13a577f0a90>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "data_dim = 16\n",
    "timesteps = 8\n",
    "num_classes = 10\n",
    "\n",
    "# expected input data shape: (batch_size, timesteps, data_dim)\n",
    "model = Sequential(name = \"HIHIH\")\n",
    "model.add(LSTM(32, return_sequences=True,\n",
    "               input_shape=(timesteps, data_dim), name = \"First_LSTM\"))  # returns a sequence of vectors of dimension 32\n",
    "#model.add(LSTM(32, return_sequences=True))  # returns a sequence of vectors of dimension 32\n",
    "model.add(LSTM(32, name = \"Second_LSTM\") )  # return a single vector of dimension 32\n",
    "model.add(Dense(10, activation='softmax', name = \"Output_Layer_softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Generate dummy training data\n",
    "x_train = np.random.random((1000, timesteps, data_dim))\n",
    "y_train = np.random.random((1000, num_classes))\n",
    "\n",
    "# Generate dummy validation data\n",
    "x_val = np.random.random((100, timesteps, data_dim))\n",
    "y_val = np.random.random((100, num_classes))\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=64, epochs=5,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file=os.path.join(figDir,'modelExample.png'), show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "timesteps = 100\n",
    "num_classes = 4\n",
    "\n",
    "# expected input data shape: (batch_size, timesteps, data_dim)\n",
    "\n",
    "# Generate dummy training data\n",
    "x_train = np.random.random((1000, timesteps))\n",
    "y_train = np.floor(x_train*4)\n",
    "s = pd.Series(y_train.reshape(-1, ))\n",
    "aa = list(y_train.shape)\n",
    "aa.append(-1)\n",
    "yy = np.array(pd.get_dummies(s)).reshape(aa)\n",
    "y_train = yy\n",
    "\n",
    "x_train = x_train.reshape(1000, 100,-1 )\n",
    "\n",
    "\n",
    "\n",
    "# Generate dummy validation data\n",
    "x_val = np.random.random((1000, timesteps))\n",
    "y_val = np.floor(x_val*4)\n",
    "s = pd.Series(y_val.reshape(-1, ))\n",
    "aa = list(y_val.shape)\n",
    "aa.append(-1)\n",
    "yy = np.array(pd.get_dummies(s)).reshape(aa)\n",
    "y_val = yy\n",
    "x_val = x_val.reshape(1000, 100,-1 )\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(1, input_shape=(100,1)))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=64, epochs=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.random.random((1000, timesteps))\n",
    "y_train = np.floor(x_train*4)\n",
    "s = pd.Series(y_train.reshape(-1, ))\n",
    "aa = list(y_train.shape)\n",
    "aa.append(-1)\n",
    "yy = np.array(pd.get_dummies(s)).reshape(aa)\n",
    "y_train = yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = x_train.reshape(1000, 100,-1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_train[1,:])\n",
    "plt.plot(yy[1,:,:] * 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(yy[1,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Example script showing how to use a stateful LSTM model\n",
    "and how its stateless counterpart performs.\n",
    "More documentation about the Keras LSTM model can be found at\n",
    "https://keras.io/layers/recurrent/#lstm\n",
    "The models are trained on an input/output pair, where\n",
    "the input is a generated uniformly distributed\n",
    "random sequence of length = \"input_len\",\n",
    "and the output is a moving average of the input with window length = \"tsteps\".\n",
    "Both \"input_len\" and \"tsteps\" are defined in the \"editable parameters\" section.\n",
    "A larger \"tsteps\" value means that the LSTM will need more memory\n",
    "to figure out the input-output relationship.\n",
    "This memory length is controlled by the \"lahead\" variable (more details below).\n",
    "The rest of the parameters are:\n",
    "- input_len: the length of the generated input sequence\n",
    "- lahead: the input sequence length that the LSTM\n",
    "  is trained on for each output point\n",
    "- batch_size, epochs: same parameters as in the model.fit(...) function\n",
    "When lahead > 1, the model input is preprocessed to a \"rolling window view\"\n",
    "of the data, with the window length = \"lahead\".\n",
    "This is similar to sklearn's \"view_as_windows\"\n",
    "with \"window_shape\" being a single number\n",
    "Ref: http://scikit-image.org/docs/0.10.x/api/skimage.util.html#view-as-windows\n",
    "When lahead < tsteps, only the stateful LSTM converges because its\n",
    "statefulness allows it to see beyond the capability that lahead\n",
    "gave it to fit the n-point average. The stateless LSTM does not have\n",
    "this capability, and hence is limited by its \"lahead\" parameter,\n",
    "which is not sufficient to see the n-point average.\n",
    "When lahead >= tsteps, both the stateful and stateless LSTM converge.\n",
    "'''\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# EDITABLE PARAMETERS\n",
    "# Read the documentation in the script head for more details\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "# length of input\n",
    "input_len = 1000\n",
    "\n",
    "# The window length of the moving average used to generate\n",
    "# the output from the input in the input/output pair used\n",
    "# to train the LSTM\n",
    "# e.g. if tsteps=2 and input=[1, 2, 3, 4, 5],\n",
    "#      then output=[1.5, 2.5, 3.5, 4.5]\n",
    "tsteps = 100\n",
    "\n",
    "# The input sequence length that the LSTM is trained on for each output point\n",
    "lahead = 1\n",
    "\n",
    "# training parameters passed to \"model.fit(...)\"\n",
    "batch_size = 1\n",
    "epochs = 20\n",
    "\n",
    "# ------------\n",
    "# MAIN PROGRAM\n",
    "# ------------\n",
    "\n",
    "print(\"*\" * 33)\n",
    "if lahead >= tsteps:\n",
    "    print(\"STATELESS LSTM WILL ALSO CONVERGE\")\n",
    "else:\n",
    "    print(\"STATELESS LSTM WILL NOT CONVERGE\")\n",
    "print(\"*\" * 33)\n",
    "\n",
    "np.random.seed(1986)\n",
    "\n",
    "print('Generating Data...')\n",
    "\n",
    "\n",
    "def gen_uniform_amp(amp=1, xn=10000):\n",
    "    \"\"\"Generates uniform random data between\n",
    "    -amp and +amp\n",
    "    and of length xn\n",
    "    Arguments:\n",
    "        amp: maximum/minimum range of uniform data\n",
    "        xn: length of series\n",
    "    \"\"\"\n",
    "    data_input = (np.sin(np.arange(0,10,step = 5/xn))+ \n",
    "    np.random.randn(len(np.arange(0,10,step = 5/xn)))*0.2)\n",
    "    data_input = pd.DataFrame(data_input)\n",
    "    return data_input\n",
    "\n",
    "# Since the output is a moving average of the input,\n",
    "# the first few points of output will be NaN\n",
    "# and will be dropped from the generated data\n",
    "# before training the LSTM.\n",
    "# Also, when lahead > 1,\n",
    "# the preprocessing step later of \"rolling window view\"\n",
    "# will also cause some points to be lost.\n",
    "# For aesthetic reasons,\n",
    "# in order to maintain generated data length = input_len after pre-processing,\n",
    "# add a few points to account for the values that will be lost.\n",
    "to_drop = max(tsteps - 1, lahead - 1)\n",
    "data_input = gen_uniform_amp(amp=0.1, xn=input_len + to_drop)\n",
    "\n",
    "# set the target to be a N-point average of the input\n",
    "expected_output = data_input.rolling(window=tsteps, center=True).mean()\n",
    "\n",
    "# when lahead > 1, need to convert the input to \"rolling window view\"\n",
    "# https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html\n",
    "if lahead > 1:\n",
    "    data_input = np.repeat(data_input.values, repeats=lahead, axis=1)\n",
    "    data_input = pd.DataFrame(data_input)\n",
    "    for i, c in enumerate(data_input.columns):\n",
    "        data_input[c] = data_input[c].shift(i)\n",
    "\n",
    "# drop the nan\n",
    "expected_output = expected_output[to_drop:]\n",
    "data_input = data_input[to_drop:]\n",
    "\n",
    "print('Input shape:', data_input.shape)\n",
    "print('Output shape:', expected_output.shape)\n",
    "print('Input head: ')\n",
    "print(data_input.head())\n",
    "print('Output head: ')\n",
    "print(expected_output.head())\n",
    "print('Input tail: ')\n",
    "print(data_input.tail())\n",
    "print('Output tail: ')\n",
    "print(expected_output.tail())\n",
    "\n",
    "print('Plotting input and expected output')\n",
    "plt.plot(data_input[0][:1000], '.')\n",
    "plt.plot(expected_output[0][:1000], '-')\n",
    "plt.legend(['Input', 'Expected output'])\n",
    "plt.title('Input')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def create_model(stateful):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(20,\n",
    "              input_shape=(lahead, 1),\n",
    "              batch_size=batch_size,\n",
    "              stateful=stateful))\n",
    "    model.add(Dense(y_train.shape[1], activation = \"linear\"))\n",
    "    \n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "print('Creating Stateful Model...')\n",
    "model_stateful = create_model(stateful=True)\n",
    "\n",
    "\n",
    "# split train/test data\n",
    "def split_data(x, y, ratio=0.8):\n",
    "    to_train = int(input_len * ratio)\n",
    "    # tweak to match with batch_size\n",
    "    to_train -= to_train % batch_size\n",
    "\n",
    "    x_train = x[:to_train]\n",
    "    y_train = y[:to_train]\n",
    "    x_test = x[to_train:]\n",
    "    y_test = y[to_train:]\n",
    "\n",
    "    # tweak to match with batch_size\n",
    "    to_drop = x.shape[0] % batch_size\n",
    "    if to_drop > 0:\n",
    "        x_test = x_test[:-1 * to_drop]\n",
    "        y_test = y_test[:-1 * to_drop]\n",
    "\n",
    "    # some reshaping\n",
    "    reshape_3 = lambda x: x.values.reshape((x.shape[0], x.shape[1], 1))\n",
    "    x_train = reshape_3(x_train)\n",
    "    x_test = reshape_3(x_test)\n",
    "\n",
    "    reshape_2 = lambda x: x.values.reshape((x.shape[0], 1))\n",
    "    y_train = reshape_2(y_train)\n",
    "    y_test = reshape_2(y_test)\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = split_data(data_input, expected_output)\n",
    "print('x_train.shape: ', x_train.shape)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('x_test.shape: ', x_test.shape)\n",
    "print('y_test.shape: ', y_test.shape)\n",
    "\n",
    "print('Training')\n",
    "for i in range(epochs):\n",
    "    print('Epoch', i + 1, '/', epochs)\n",
    "    # Note that the last state for sample i in a batch will\n",
    "    # be used as initial state for sample i in the next batch.\n",
    "    # Thus we are simultaneously training on batch_size series with\n",
    "    # lower resolution than the original series contained in data_input.\n",
    "    # Each of these series are offset by one step and can be\n",
    "    # extracted with data_input[i::batch_size].\n",
    "    model_stateful.fit(x_train,\n",
    "                       y_train,\n",
    "                       batch_size=batch_size,\n",
    "                       epochs=1,\n",
    "                       verbose=1,\n",
    "                       validation_data=(x_test, y_test),\n",
    "                       shuffle=False)\n",
    "    model_stateful.reset_states()\n",
    "\n",
    "print('Predicting')\n",
    "predicted_stateful = model_stateful.predict(x_test, batch_size=batch_size)\n",
    "\n",
    "print('Creating Stateless Model...')\n",
    "model_stateless = create_model(stateful=False)\n",
    "\n",
    "print('Training')\n",
    "model_stateless.fit(x_train,\n",
    "                    y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    shuffle=False)\n",
    "\n",
    "print('Predicting')\n",
    "predicted_stateless = model_stateless.predict(x_test, batch_size=batch_size)\n",
    "\n",
    "# ----------------------------\n",
    "\n",
    "print('Plotting Results')\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(y_test)\n",
    "plt.title('Expected')\n",
    "plt.subplot(3, 1, 2)\n",
    "# drop the first \"tsteps-1\" because it is not possible to predict them\n",
    "# since the \"previous\" timesteps to use do not exist\n",
    "plt.plot((y_test - predicted_stateful).flatten()[tsteps - 1:])\n",
    "plt.title('Stateful: Expected - Predicted')\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot((y_test - predicted_stateless).flatten())\n",
    "plt.title('Stateless: Expected - Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print('Plotting input and expected output')\n",
    "plt.plot(data_input[0][:1000], '.')\n",
    "plt.plot(expected_output[0][:1000], '-')\n",
    "plt.legend(['Input', 'Expected output'])\n",
    "plt.title('Input')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "from numpy import array\n",
    "from numpy import cumsum\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    " \n",
    "# create a sequence classification instance\n",
    "def get_sequence(n_timesteps):    \n",
    "    # create a sequence of random numbers in [0,1]\n",
    "    X = array([random() for _ in range(n_timesteps)])\n",
    "    # calculate cut-off value to change class values\n",
    "    limit = n_timesteps/4.0\n",
    "    # determine the class outcome for each item in cumulative sequence\n",
    "    y = array([0 if x < limit else 1 for x in cumsum(X)])\n",
    "    # reshape input and output data to be suitable for LSTMs\n",
    "    X = X.reshape(1, n_timesteps, 1)\n",
    "    y = y.reshape(1, n_timesteps, 1)\n",
    "    return X, y\n",
    " \n",
    "# define problem properties\n",
    "n_timesteps = 10\n",
    "# define LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(20, input_shape=(n_timesteps, 1), return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(1, activation='sigmoid')))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "# train LSTM\n",
    "for epoch in range(1000):\n",
    "    # generate new random sequence\n",
    "    X,y = get_sequence(n_timesteps)\n",
    "    # fit model for one epoch on this sequence\n",
    "    model.fit(X, y, epochs=1, batch_size=1, verbose=2)\n",
    "# evaluate LSTM\n",
    "X,y = get_sequence(n_timesteps)\n",
    "yhat = model.predict_classes(X, verbose=0)\n",
    "for i in range(n_timesteps):\n",
    "    print('Expected:', y[0, i], 'Predicted', yhat[0, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readMyFile(filename):\n",
    "    \n",
    "    '''Read in csv 10x faster than pandas'''\n",
    "    \n",
    "    tmpdta = []\n",
    " \n",
    "    with open(filename, newline=\"\\n\") as csvDataFile:\n",
    "        csvReader = csv.reader(csvDataFile, delimiter=' ', quoting=csv.QUOTE_NONNUMERIC)\n",
    "        for row in csvReader:\n",
    "            tmpdta.append(row)\n",
    " \n",
    "    return(pd.DataFrame(np.transpose(tmpdta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fft class\n",
    "\n",
    "class fft_:\n",
    "    \n",
    "    '''\n",
    "    Does fft spectrum with accelerometer data\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, timesteps, sigl, cutoff = 200):\n",
    "        self.timesteps = timesteps\n",
    "        self.sigl = sigl - np.mean(sigl)\n",
    "        self.log_rate = np.round(1/np.mean(np.diff(timesteps)))\n",
    "        \n",
    "    \n",
    "    def butter_highpass(self, order=5):\n",
    "        self.order = order\n",
    "        nyq = 0.5 * self.log_rate\n",
    "        normal_cutoff = self.cutoff / nyq\n",
    "        b, a = signal.butter(self.order, normal_cutoff, btype='high', analog=False)\n",
    "        return b,a\n",
    "\n",
    "    def butter_highpass_filter(self, sigToFilter, cutoff = 200, order=5):\n",
    "        self.cutoff = cutoff\n",
    "        b, a = self.butter_highpass()\n",
    "        newSig = np.concatenate([np.flip(sigToFilter[0:1000], axis = 0),\n",
    "                                 sigToFilter, \n",
    "                                 np.flip(sigToFilter[(len(sigToFilter)-1000):len(sigToFilter)], axis = 0) ])\n",
    "        self.newSig = newSig\n",
    "        y = signal.filtfilt(b, a, newSig)\n",
    "        self.filtered_sigl = y[1000:(len(sigToFilter)+1000)]\n",
    "        \n",
    "    \n",
    "    def filterAcc(self):\n",
    "        self.butter_highpass_filter(sigToFilter= self.sigl, cutoff = 220)\n",
    "        self.filtered_acc = self.filtered_sigl - np.mean(self.filtered_sigl)\n",
    "    \n",
    "    \n",
    "    def doubleIntegrate(self, sigToIntegrate):\n",
    "        vel = np.cumsum(sigToIntegrate)/self.log_rate\n",
    "        pos = np.cumsum(vel - np.mean(vel)) / self.log_rate\n",
    "        self.pos_unfilt = pos - np.mean(pos)\n",
    "        \n",
    "        # highpass filter position\n",
    "        self.butter_highpass_filter(sigToFilter= pos, cutoff = 100)\n",
    "        self.pos = self.filtered_sigl - np.mean(self.filtered_sigl)\n",
    "         \n",
    "    \n",
    "    def fft_fit(self, inputSignal):\n",
    "        n =len(inputSignal) # length of the sigl\n",
    "        k = np.arange(n, step = 1)\n",
    "        T = n/self.log_rate\n",
    "        frq = k/T # two sides frequency range\n",
    "        frq = frq[range(int(n/2))] # one side frequency range\n",
    "\n",
    "        # fft computing and normalization (note that *2 is so that it is scaled properly)\n",
    "        Y = np.fft.fft(inputSignal)/n *2 \n",
    "        Y = Y[range(int(n/2))]\n",
    "\n",
    "        # calculate top frequency\n",
    "        ind = np.argpartition(abs(Y), -4)[-4:]\n",
    "        \n",
    "        # Find highest point on the spectrum\n",
    "        self.peakFrq = frq[ind[::-1]]\n",
    "        self.pwr = (abs(Y)[ind[::-1]])\n",
    "        \n",
    "        self.dominant_freq = [x for (y,x) in sorted(zip(self.pwr,self.peakFrq), reverse = True)][0]\n",
    "        self.max_amp = self.pwr[self.peakFrq == self.dominant_freq]\n",
    "        self.Y = Y\n",
    "        self.frq = frq\n",
    "        self.fftSignal = inputSignal\n",
    "        \n",
    "        \n",
    "        \n",
    "    def plot_fft(self, title = \"\", ylab = \"\", showPlt = True):    \n",
    "        plt.figure(figsize=(10,4))\n",
    "        gs = gridspec.GridSpec(1, 2, width_ratios=[2,2]) \n",
    "\n",
    "        # create subplot 1\n",
    "        ax1 = plt.subplot(gs[0])\n",
    "        ax1.plot(self.timesteps[0:len(self.fftSignal)],self.fftSignal, color = 'black', linewidth=0.5)\n",
    "        ax1.set_title(title + \" signal\")\n",
    "        ax1.set_ylabel(ylab)\n",
    "        ax1.set_xlabel(\"Time (s)\")\n",
    "    \n",
    "        # subplot 2\n",
    "        ax2 = plt.subplot(gs[1])\n",
    "        ax2.plot(self.frq, abs(self.Y), color = \"black\", linewidth=0.5)\n",
    "        ax2.set_ylabel(ylab)\n",
    "        ax2.set_xlabel(\"Frequency (Hz)\")\n",
    "        if(not np.isinf(self.dominant_freq)):\n",
    "            ax2.plot(self.dominant_freq, self.max_amp,'o', color = 'black', markersize = 5)\n",
    "            ax2.annotate(str(self.dominant_freq) + ' Hz', \n",
    "                     xy=(self.dominant_freq, self.max_amp), \n",
    "                     xytext=(self.dominant_freq + 40, \n",
    "                             self.max_amp-0.01*self.max_amp), size = 12)\n",
    "            ax2.set_xlim(-0, 1003)\n",
    "            ax2.set_title(title + \" FFT spectrum\")\n",
    "        if showPlt: \n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowsOrMacDirectories():\n",
    "    \"\"\" Sets base directories for win or mac\n",
    "\n",
    "       \n",
    "    \"\"\"\n",
    "    if os.environ['COMPUTERNAME'] == 'SHEALMACLEARN':\n",
    "        DropboxDirect = os.path.join(\"D:\\Dropbox\")\n",
    "#     elif sys.platform.startswith('linux') or sys.platform.startswith('cygwin'):\n",
    "#         # this excludes your current terminal \"/dev/tty\"\n",
    "    elif sys.platform.startswith('darwin'):\n",
    "        DropboxDirect = os.path.join(\"/Users/cswitzer/Dropbox\")\n",
    "    else:\n",
    "        raise EnvironmentError('Unknown computer platform')\n",
    "    \n",
    "    baseDir = os.getcwd()\n",
    "    dataDir = os.path.join(DropboxDirect, 'SonicationBehavior', 'SonBehData')\n",
    "    figDir = os.path.join(DropboxDirect, 'SonicationBehavior', 'SonBehFigs')\n",
    "    return baseDir, dataDir, figDir\n",
    "\n",
    "\n",
    "baseDir, dataDir, figDir = windowsOrMacDirectories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in Heavy/Light data\n",
    "HeavyLight = os.path.join(dataDir, \"02_HeavyLight_cleaned.csv\")\n",
    "hl = pd.read_csv(HeavyLight)\n",
    "hl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dd = os.path.join(dataDir, \"SonicationBehavior_HeavyLight\")\n",
    "\n",
    "allFolders = np.unique(hl.accFileAndFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample a random recording\n",
    "# save example figures\n",
    "\n",
    "#ii = np.random.randint(low = 0, high = hl.shape[0], size = 1)[0]\n",
    "buzzFile = os.path.join(dd, hl.accFileAndFolder[ii].split(\"_ampFreq.txt\")[0].replace(\"/\", \"\\\\\"), hl.accFile[ii])\n",
    "#buzzFile = combinedDF.loc[combinedDF.noiseVar > 10,\"fileName\"].tolist()[0]#\n",
    "tmpdf1 = readMyFile(buzzFile)\n",
    "timesteps = tmpdf1.iloc[:,0 ]\n",
    "sig = np.array(tmpdf1.iloc[:,1]*1000 / 10.17)\n",
    "\n",
    "\n",
    "sigProc = fft_(timesteps, sig)\n",
    "sigProc.fft_fit(sigProc.sigl)\n",
    "print(sigProc.dominant_freq, hl.accFile[ii])\n",
    "sigProc.plot_fft(title = \"Unfiltered Acceleration\", ylab = \"Acceleration (m/s/s)\")\n",
    "\n",
    "sigProc.filterAcc()\n",
    "plt.plot(sigProc.filtered_acc)\n",
    "plt.grid(True)\n",
    "sigProc.fft_fit(sigProc.filtered_acc)\n",
    "sigProc.plot_fft(title = \"Filtered Acceleration\", ylab = \"Acceleration (m/s/s)\")\n",
    "\n",
    "sigProc.doubleIntegrate(sigProc.filtered_sigl)\n",
    "sigProc.fft_fit(sigProc.pos_unfilt)\n",
    "#sigProc.plot_fft(title =  \"Position (no filt)\")\n",
    "\n",
    "sigProc.fft_fit(sigProc.pos)\n",
    "sigProc.plot_fft(title =  \"Position (h.p. filt'd')\")\n",
    "\n",
    "\n",
    "# envelope\n",
    "accMxs = pd.Series(abs(sigProc.filtered_acc -np.mean(sigProc.filtered_acc))).rolling(int(2000), center = True, min_periods = 1).max().tolist()\n",
    "plt.plot(abs(sigProc.filtered_acc -np.mean(sigProc.filtered_acc)))\n",
    "plt.plot(accMxs)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "mxs = pd.Series(abs(sigProc.pos)).rolling(int(700), center = True, min_periods = 1).max().tolist()\n",
    "# plt.plot(abs(sigProc.pos -np.mean(sigProc.pos)))\n",
    "# plt.plot(mxs)\n",
    "# plt.show()\n",
    "\n",
    "aa = np.array(np.where((np.array(accMxs) > 2.0) & (np.arange(0, len(accMxs)) < 18000) & (np.arange(0, len(accMxs)) > 2000)))\n",
    "bb = aa.flatten()\n",
    "\n",
    "if bb.shape[0] > 0:\n",
    "\n",
    "    plt.plot(sigProc.pos )\n",
    "    plt.title(\"position with amplitude drawn\")\n",
    "\n",
    "\n",
    "    plt.plot(bb, sigProc.pos[bb])\n",
    "\n",
    "    maxCut = np.array(mxs)[bb]\n",
    "    mm = np.mean(np.unique(maxCut))\n",
    "\n",
    "    plt.hlines(xmin = 0, xmax = 20000, y = [mm, - mm])\n",
    "    print(np.mean(np.unique(mm)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # write data to .csv file\n",
    "# buzzClassDataDir = os.path.join(\"D:\\Dropbox\\SonicationBehavior\\SonBehData\\BuzzPartClassification\")\n",
    "# buzzClassDataDir\n",
    "\n",
    "# noise = [0,0]\n",
    "# wing = [ 0,0]\n",
    "# buzz = [0,20000]\n",
    "\n",
    "# if(not os.path.exists(os.path.join(buzzClassDataDir, 'BuzzClassifications.csv'))):\n",
    "#     with open(os.path.join(buzzClassDataDir, 'BuzzClassifications.csv'), 'a') as the_file: \n",
    "#         print(\"Writing Header\")\n",
    "#         the_file.write('fileName,noise1,noise2,wing1,wing2,buzz1,buzz2\\n')\n",
    "        \n",
    "\n",
    "\n",
    "# with open(os.path.join(buzzClassDataDir, 'BuzzClassifications.csv'), 'a') as the_file: \n",
    "#     the_file.write(str(buzzFile) + \",\" + ','.join(map(str, np.hstack([noise, wing, buzz]))) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learn from manually-classified data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buzzClassDataDir = os.path.join(\"D:\\Dropbox\\SonicationBehavior\\SonBehData\\BuzzPartClassification\")\n",
    "buzzClass = pd.read_csv(os.path.join(buzzClassDataDir, 'BuzzClassifications.csv'))\n",
    "print(buzzClass.shape)\n",
    "buzzClass.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicated rows\n",
    "buzzClass.drop_duplicates(subset = \"fileName\", inplace = True)\n",
    "buzzClass.reset_index(drop = True, inplace = True)\n",
    "buzzClass.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in each recording, and calculate variance for different parts of the recordings\n",
    "\n",
    "kk = 3\n",
    "tmpRec = readMyFile(buzzClass.fileName[kk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuzzNoiseWing:\n",
    "    \n",
    "    '''\n",
    "    Splits recording into buzz, noise, wingbeat\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, fileName):\n",
    "        self.fileName = fileName\n",
    "        self.recording = readMyFile(fileName)\n",
    "        self.metaDat = buzzClass.loc[buzzClass.fileName == self.fileName, :]\n",
    "        self.noisePts = np.array(self.metaDat.iloc[0, 1:3]).astype(int)\n",
    "        self.wingPts = np.array(self.metaDat.iloc[0, 3:5]).astype(int)\n",
    "        self.buzzPts = np.array(self.metaDat.iloc[0, 5:7]).astype(int)\n",
    "        self.buzzParts = self.recording.iloc[np.arange(self.buzzPts[0], self.buzzPts[1]),:]\n",
    "        self.noiseParts = self.recording.iloc[np.arange(self.noisePts[0], self.noisePts[1]),:]\n",
    "        self.wingParts = self.recording.iloc[np.arange(self.wingPts[0], self.wingPts[1]),:]\n",
    "        \n",
    "    def euclidean_dist(self, x): # same as L2 Norm\n",
    "        return x.dot(x)/len(x)\n",
    "    \n",
    "    def calcParts(self, plot = False, smallPlot = False):\n",
    "        \n",
    "        self.noiseWingBuzz = []\n",
    "        for recPart in [self.noiseParts, self.wingParts, self.buzzParts]:\n",
    "            self.sig = []\n",
    "            \n",
    "            print(recPart.shape)\n",
    "            \n",
    "            if (recPart.shape[0] > 0):\n",
    "                # process parts of recording\n",
    "                self.sig = np.array(recPart.iloc[:,1]*1000 / 10.17)\n",
    "                sigProc = fft_(recPart.iloc[:,0], self.sig)\n",
    "                sigProc.fft_fit(sigProc.sigl)\n",
    "                if plot:\n",
    "                    sigProc.plot_fft(title = \"Original Acceleration\")\n",
    "\n",
    "                sigProc.filterAcc()\n",
    "                if plot:\n",
    "                    plt.plot(sigProc.filtered_acc)\n",
    "                    plt.grid(True)\n",
    "                sigProc.fft_fit(sigProc.filtered_acc)\n",
    "                if plot:\n",
    "                    sigProc.plot_fft(title = \"Filtered Acceleration\")\n",
    "                #self.accVars = pd.Series(sigProc.filtered_acc - np.mean(sigProc.filtered_acc)).rolling(int(3000), center = True, min_periods = 1).apply(self.euclidean_dist).tolist()\n",
    "                #self.accVars = pd.Series((sigProc.filtered_acc - np.mean(sigProc.filtered_acc))).rolling(int(3000), center = True, min_periods = 1).var().tolist()\n",
    "                self.accVars = pd.Series(abs(sigProc.filtered_acc - np.mean(sigProc.filtered_acc))).rolling(int(3000), center = True, min_periods = 1).max().tolist()\n",
    "\n",
    "                if plot or smallPlot:\n",
    "                    plt.plot(self.accVars)\n",
    "                    plt.show()\n",
    "                    print(np.mean(self.accVars))\n",
    "                self.noiseWingBuzz.append(np.mean(self.accVars))\n",
    "            else:\n",
    "                self.noiseWingBuzz.append(np.nan)\n",
    "\n",
    "                \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk +=1\n",
    "tt = BuzzNoiseWing(buzzClass.fileName[kk])\n",
    "tt.calcParts(plot = True, smallPlot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample a random recording\n",
    "# save example figures\n",
    "\n",
    "#ii = np.random.randint(low = 0, high = hl.shape[0], size = 1)[0]\n",
    "buzzFile = os.path.join(dd, hl.accFileAndFolder[ii].split(\"_ampFreq.txt\")[0].replace(\"/\", \"\\\\\"), hl.accFile[ii])\n",
    "#buzzFile = combinedDF.loc[combinedDF.noiseVar > 10,\"fileName\"].tolist()[0]#\n",
    "tmpdf1 = readMyFile(buzzFile)\n",
    "timesteps = tmpdf1.iloc[:,0 ]\n",
    "sig = np.array(tmpdf1.iloc[:,1]*1000 / 10.17)\n",
    "\n",
    "\n",
    "sigProc = fft_(timesteps, sig)\n",
    "sigProc.fft_fit(sigProc.sigl)\n",
    "print(sigProc.dominant_freq, hl.accFile[ii])\n",
    "sigProc.plot_fft(title = \"Unfiltered acceleration\", ylab = \"Acceleration (m/s/s)\", showPlt = False)\n",
    "plt.savefig(os.path.join(figDir, \"UnfilteredAccExample.pdf\"), width = 10, height = 4)\n",
    "plt.show()\n",
    "\n",
    "sigProc.filterAcc()\n",
    "#plt.plot(sigProc.filtered_acc)\n",
    "#plt.grid(True)\n",
    "sigProc.fft_fit(sigProc.filtered_acc)\n",
    "sigProc.plot_fft(title = \"Filtered acceleration\", ylab = \"Acceleration (m/s/s)\", showPlt=False)\n",
    "plt.savefig(os.path.join(figDir, \"FilteredAccExample.pdf\"), width = 10, height = 4)\n",
    "plt.show()\n",
    "\n",
    "sigProc.doubleIntegrate(sigProc.filtered_sigl)\n",
    "sigProc.fft_fit(sigProc.pos_unfilt)\n",
    "sigProc.plot_fft(title =  \"Unfiltered position\", ylab = \"Position (m)\", showPlt = False)\n",
    "plt.savefig(os.path.join(figDir, \"UnfilteredPositionExample.pdf\"), width = 10, height = 4)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "sigProc.fft_fit(sigProc.pos)\n",
    "sigProc.plot_fft(title =  \"Filtered position\", ylab = \"Position (m)\", showPlt = False)\n",
    "plt.savefig(os.path.join(figDir, \"FilteredPosExample.pdf\"), width = 10, height = 4)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# envelope\n",
    "accMxs = pd.Series(abs(sigProc.filtered_acc -np.mean(sigProc.filtered_acc))).rolling(int(1000), center = True, min_periods = 1).max().tolist()\n",
    "plt.plot(abs(sigProc.filtered_acc -np.mean(sigProc.filtered_acc)))\n",
    "plt.plot(accMxs)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "mxs = pd.Series(abs(sigProc.pos)).rolling(int(700), center = True, min_periods = 1).max().tolist()\n",
    "# plt.plot(abs(sigProc.pos -np.mean(sigProc.pos)))\n",
    "# plt.plot(mxs)\n",
    "# plt.show()\n",
    "\n",
    "aa = np.array(np.where((np.array(accMxs) > 2.5) & (np.arange(0, len(accMxs)) < 18000) & (np.arange(0, len(accMxs)) > 2000)))\n",
    "bb = aa.flatten()\n",
    "\n",
    "if bb.shape[0] > 0:\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    ax.plot(sigProc.timesteps[0:(len(sigProc.pos))],sigProc.pos*1000,  alpha = 0.2, c=\"black\" )\n",
    "    #ax.set_title(\"Position signal with sonication\")\n",
    "\n",
    "    cc = sigProc.timesteps[0:(len(sigProc.pos))]\n",
    "    \n",
    "    ax.plot(cc[bb], sigProc.pos[bb]*1000, c= 'black')\n",
    "\n",
    "    maxCut = np.array(mxs)[bb]\n",
    "    mm = np.mean((maxCut))\n",
    "    ax.set_xlim(0,0.1)\n",
    "    ax.set_ylabel(\"Position (mm)\")\n",
    "    ax.set_xlabel(\"Time (s)\")\n",
    "\n",
    "    ax.hlines(xmin = -0.01, xmax =np.max(cc[bb]), y = [mm*1000, - mm*1000], colors = 'grey',   linestyles= \"--\")\n",
    "    #plt.plot(mxs)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(figDir, \"PositionBuzzAccented.pdf\"), width = 10, height = 7)\n",
    "    print(np.mean(np.unique(mm)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigNoiseWingBuzzVar = []\n",
    "\n",
    "for kk in np.arange(buzzClass.shape[0]):\n",
    "    print(kk)\n",
    "    tt = BuzzNoiseWing(buzzClass.fileName[kk])\n",
    "    tt.calcParts()\n",
    "    bigNoiseWingBuzzVar.append(tt.noiseWingBuzz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varDF = pd.DataFrame(bigNoiseWingBuzzVar)\n",
    "varDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedDF = pd.concat([buzzClass.reset_index(drop=True), varDF], axis = 1)\n",
    "combinedDF.rename(columns = {0:'noiseVar', 1:'wingVar', 2:'buzzVar'}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_size = 0.5; min_edge = 0; max_edge = 20\n",
    "N = (max_edge-min_edge)/bin_size; Nplus1 = int(N) + 1\n",
    "bin_list = np.linspace(min_edge, max_edge, Nplus1)\n",
    "\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1)\n",
    "ax0 = axes\n",
    "n_bins = 10\n",
    "x = np.array([np.hstack([combinedDF.noiseVar[~np.isnan(combinedDF.noiseVar)], \n",
    "                                   combinedDF.wingVar[~np.isnan(combinedDF.wingVar)]]), \n",
    "               combinedDF.buzzVar[(~np.isnan(combinedDF.buzzVar)) & (combinedDF.buzzVar<20)]])\n",
    "colors = ['Signal Noise or Wingbeat', 'Sonication']\n",
    "ax0.hist(x, bin_list, normed=1, histtype='bar', label=colors)\n",
    "ax0.legend(prop={'size': 10})\n",
    "ax0.set_ylabel(\"Density\")\n",
    "ax0.set_xlabel(\"Variance of accelerations\")\n",
    "ax0.set_xlim(0, 10)\n",
    "#ax0.set_title('Noise, Wingbeat, and Sonications')\n",
    "plt.savefig(os.path.join(figDir, \"SonicationClassificationVars.pdf\"), width = 5, height = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(x[1], bins=bin_list, label = \"Sonication\")\n",
    "sns.distplot(x[0],bins=bin_list, label = \"Signal Noise or Wingbeat\")\n",
    "plt.xlabel(\"Variance of accelerations\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.xlim(0, 15)\n",
    "plt.savefig(os.path.join(figDir, \"SonicationClassificationDensityVars.pdf\"), width = 5, height = 4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1)\n",
    "ax3 = axes\n",
    "ax3.hist(x, n_bins, histtype='step', stacked=False, normed = 1)\n",
    "ax3.set_title('different sample sizes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedDF.loc[combinedDF.buzzVar < 2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk = 62\n",
    "tt = BuzzNoiseWing(buzzClass.fileName[kk])\n",
    "tt.calcParts(plot = True, smallPlot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = readMyFile(buzzClass.fileName[kk])\n",
    "plt.plot(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = np.array(tt.buzzParts.iloc[:,1]*1000 / 10.17)\n",
    "sigProc = fft_(tt.buzzParts.iloc[:,0], sig)\n",
    "sigProc.fft_fit(sigProc.sigl)\n",
    "\n",
    "plt.plot(sigProc.sigl)\n",
    "sigProc.dominant_freq\n",
    "sigProc.plot_fft(title = \"Original Acceleration\")\n",
    "sigProc.filterAcc()\n",
    "plt.plot(sigProc.filtered_acc)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigProc.fft_fit(sigProc.filtered_acc)\n",
    "len(sigProc.fftSignal)\n",
    "sigProc.plot_fft(title = \"Filtered Acceleration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accMxs = pd.Series(abs(sigProc.filtered_acc -np.mean(sigProc.filtered_acc))).rolling(int(1000), center = True, min_periods = 1).var().tolist()\n",
    "plt.plot(accMxs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_fit(inputSignal, log_rate = 20000):\n",
    "    n =len(inputSignal) # length of the sigl\n",
    "    k = np.arange(n, step = 1)\n",
    "    T = n/log_rate\n",
    "    frq = k/T # two sides frequency range\n",
    "    frq = frq[range(int(n/2))] # one side frequency range\n",
    "\n",
    "    # fft computing and normalization (note that *2 is so that it is scaled properly)\n",
    "    Y = np.fft.fft(inputSignal)/n *2 \n",
    "    Y = Y[range(int(n/2))]\n",
    "\n",
    "    # calculate top frequency\n",
    "    ind = np.argpartition(abs(Y), -4)[-4:]\n",
    "\n",
    "    # Find highest point on the spectrum\n",
    "    peakFrq = frq[ind[::-1]]\n",
    "    pwr = (abs(Y)[ind[::-1]])\n",
    "\n",
    "    dominant_freq = [x for (y,x) in sorted(zip(pwr,peakFrq), reverse = True)][0]\n",
    "    max_amp = pwr[peakFrq == dominant_freq]\n",
    "    Y = Y\n",
    "    frq = frq\n",
    "    fftSignal = inputSignal\n",
    "    return(peakFrq, pwr, dominant_freq, max_amp, Y, frq, fftSignal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peakFrq, pwr, dominant_freq, max_amp, Y, frq, fftSignal = fft_fit(sigProc.sigl)\n",
    "plt.plot(abs(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigProc.filterAcc()\n",
    "plt.plot(sigProc.filtered_acc)\n",
    "plt.grid(True)\n",
    "sigProc.fft_fit(sigProc.filtered_acc)\n",
    "sigProc.plot_fft(title = \"Filtered Acceleration\")\n",
    "accMxs = pd.Series(abs(sigProc.filtered_acc -np.mean(sigProc.filtered_acc))).rolling(int(1000), center = True, min_periods = 1).var().tolist()\n",
    "plt.plot(accMxs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tt.buzzParts.iloc[:,0], tt.sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigProc.fft_fit(sigProc.sigl)\n",
    "sigProc.plot_fft(title = \"Original Acceleration\")\n",
    "sigProc.filterAcc()\n",
    "plt.plot(sigProc.filtered_acc)\n",
    "plt.grid(True)\n",
    "sigProc.fft_fit(sigProc.filtered_acc)\n",
    "sigProc.plot_fft(title = \"Filtered Acceleration\")\n",
    "accMxs = pd.Series(abs(sigProc.filtered_acc -np.mean(sigProc.filtered_acc))).rolling(int(1000), center = True, min_periods = 1).var().tolist()\n",
    "plt.plot(accMxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "gs = gridspec.GridSpec(1, 2, width_ratios=[2,2]) \n",
    "\n",
    "# create subplot 1\n",
    "ax1 = plt.subplot(gs[0])\n",
    "ax1.plot(sigProc.timesteps[0:len(sigProc.fftSignal)],sigProc.fftSignal, color = 'black', linewidth=0.5)\n",
    "ax1.set_title(title + \" signal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigProc.timesteps[0:len(sigProc.fftSignal)].shape\n",
    "sigProc.fftSignal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaDat = buzzClass.loc[buzzClass.fileName == tt.fileName, :]\n",
    "noisePts = np.array(metaDat.iloc[0, 1:3]).astype(int)\n",
    "wingPts = np.array(metaDat.iloc[0, 3:5]).astype(int)\n",
    "buzzPts = np.array(metaDat.iloc[0, 5:7]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wingPts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not os.path.exists(os.path.join(buzzClassDataDir, 'BuzzClassifications.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldNum = 2\n",
    "try:\n",
    "    ii += 1\n",
    "except NameError:\n",
    "    print(\"well, it WASN'T defined after all!\")\n",
    "    ii = 0\n",
    "\n",
    "tmpF = os.path.join(dd, allFolders[foldNum])\n",
    "tmpDF = pd.read_csv(tmpF, header = None)\n",
    "tmpDF.columns = [\"frq\", \"MaxMinAmp\", \"fname_short\", \"dd\", \"TT\", \"AA\", \"BB\"]\n",
    "tmpDF.fname_short = [ff.strip() for ff in tmpDF.fname_short]\n",
    "\n",
    "fold = os.path.join(dd, allFolders[foldNum]).split(\"_ampFreq.txt\")[0]\n",
    "\n",
    "accRecs = [f for f in os.listdir(fold) if not f.startswith(\".\") ]\n",
    "\n",
    "ar = accRecs[ii]\n",
    "tmpdf1 = readMyFile(os.path.join(fold, ar))\n",
    "timesteps = tmpdf1.iloc[:,0 ]\n",
    "sig = np.array(tmpdf1.iloc[:,1]*1000 / 10.17)\n",
    "\n",
    "# timesteps = np.linspace(0, 0.1, num = 20000)\n",
    "# sig = 3.0*np.sin(369*2*np.pi*(timesteps + 0.003)) \n",
    "\n",
    "sigProc = fft_(timesteps, sig)\n",
    "sigProc.fft_fit(sigProc.sigl)\n",
    "sigProc.plot_fft(title = \"Original Acceleration\")\n",
    "\n",
    "\n",
    "sigProc.filterAcc()\n",
    "#plt.plot(sigProc.newSig)\n",
    "sigProc.fft_fit(sigProc.filtered_acc)\n",
    "sigProc.plot_fft(title = \"Filtered Acceleration\")\n",
    "\n",
    "\n",
    "sigProc.doubleIntegrate(sigProc.filtered_sigl)\n",
    "sigProc.fft_fit(sigProc.pos_unfilt)\n",
    "sigProc.plot_fft(title =  \"Position (no filt)\")\n",
    "\n",
    "sigProc.fft_fit(sigProc.pos)\n",
    "sigProc.plot_fft(title =  \"Position (h.p. filt'd')\")\n",
    "\n",
    "\n",
    "# envelope\n",
    "accMxs = pd.Series(abs(sigProc.filtered_acc -np.mean(sigProc.filtered_acc))).rolling(int(700), center = True, min_periods = 1).max().tolist()\n",
    "# plt.plot(abs(sigProc.filtered_acc -np.mean(sigProc.filtered_acc)))\n",
    "# plt.plot(accMxs)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "mxs = pd.Series(abs(sigProc.pos)).rolling(int(700), center = True, min_periods = 1).max().tolist()\n",
    "# plt.plot(abs(sigProc.pos -np.mean(sigProc.pos)))\n",
    "# plt.plot(mxs)\n",
    "# plt.show()\n",
    "\n",
    "aa = np.array(np.where((np.array(accMxs) > 2.0) & (np.arange(0, len(accMxs)) < 18000) & (np.arange(0, len(accMxs)) > 2000)))\n",
    "bb = aa.flatten()\n",
    "\n",
    "if bb.shape[0] > 0:\n",
    "\n",
    "    plt.plot(sigProc.pos )\n",
    "    plt.title(\"position with amplitude drawn\")\n",
    "\n",
    "\n",
    "    plt.plot(bb, sigProc.pos[bb])\n",
    "\n",
    "    maxCut = np.array(mxs)[bb]\n",
    "    mm = np.mean(np.unique(maxCut))\n",
    "\n",
    "    plt.hlines(xmin = 0, xmax = 20000, y = [mm, - mm])\n",
    "    print(np.mean(np.unique(mm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldNum = 2\n",
    "#ii = 0\n",
    "\n",
    "tmpF = os.path.join(dd, allFolders[foldNum])\n",
    "tmpDF = pd.read_csv(tmpF, header = None)\n",
    "tmpDF.columns = [\"frq\", \"MaxMinAmp\", \"fname_short\", \"dd\", \"TT\", \"AA\", \"BB\"]\n",
    "tmpDF.fname_short = [ff.strip() for ff in tmpDF.fname_short]\n",
    "\n",
    "fold = os.path.join(dd, allFolders[foldNum]).split(\"_ampFreq.txt\")[0]\n",
    "\n",
    "accRecs = [f for f in os.listdir(fold) if not f.startswith(\".\") ]\n",
    "\n",
    "ar = accRecs[ii]\n",
    "tmpdf1 = readMyFile(os.path.join(fold, ar))\n",
    "timesteps = tmpdf1.iloc[:,0 ]\n",
    "sig = np.array(tmpdf1.iloc[:,1]*1000 / 10.17)\n",
    "\n",
    "# timesteps = np.linspace(0, 0.1, num = 20000)\n",
    "# sig = 3.0*np.sin(369*2*np.pi*(timesteps + 0.003)) \n",
    "\n",
    "sigProc = fft_(timesteps, sig)\n",
    "sigProc.fft_fit(sigProc.sigl)\n",
    "sigProc.plot_fft(title = \"Original Acceleration\")\n",
    "\n",
    "\n",
    "sigProc.filterAcc()\n",
    "#plt.plot(sigProc.newSig)\n",
    "sigProc.fft_fit(sigProc.filtered_acc)\n",
    "sigProc.plot_fft(title = \"Filtered Acceleration\")\n",
    "\n",
    "\n",
    "sigProc.doubleIntegrate(sigProc.filtered_sigl)\n",
    "sigProc.fft_fit(sigProc.pos_unfilt)\n",
    "#sigProc.plot_fft(title =  \"Position (no filt)\")\n",
    "\n",
    "sigProc.fft_fit(sigProc.pos)\n",
    "#sigProc.plot_fft(title =  \"Position (h.p. filt'd')\")\n",
    "\n",
    "\n",
    "# envelope\n",
    "accMxs = pd.Series((sigProc.filtered_acc - \n",
    "                    np.mean(sigProc.filtered_acc))).rolling(int(1000), \n",
    "                                                            center = True, \n",
    "                                                            min_periods = 1).var().tolist()\n",
    "plt.plot(accMxs)\n",
    "plt.show()\n",
    "\n",
    "mxs = pd.Series(abs(sigProc.pos)).rolling(int(1000), center = True, min_periods = 1).max().tolist()\n",
    "plt.plot(abs(sigProc.pos -np.mean(sigProc.pos)))\n",
    "plt.plot(mxs)\n",
    "plt.show()\n",
    "\n",
    "aa = np.array(np.where((np.array(accMxs) > 2.0) & (np.arange(0, len(accMxs)) < 18000) & (np.arange(0, len(accMxs)) > 2000)))\n",
    "bb = aa.flatten()\n",
    "\n",
    "if bb.shape[0] > 0:\n",
    "\n",
    "    plt.plot(sigProc.pos )\n",
    "    plt.title(\"position with amplitude drawn\")\n",
    "\n",
    "\n",
    "    plt.plot(bb, sigProc.pos[bb])\n",
    "\n",
    "    maxCut = np.array(mxs)[bb]\n",
    "    mm = np.mean(np.unique(maxCut))\n",
    "\n",
    "    plt.hlines(xmin = 0, xmax = 20000, y = [mm, - mm])\n",
    "    print(np.mean(np.unique(mm)))\n",
    "    \n",
    "#ii += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(accMxs)\n",
    "plt.ylim(0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude short sequences\n",
    "cc = (np.array(accMxs) > 2.0) & (np.arange(0, len(accMxs)) < 18000) & (np.arange(0, len(accMxs)) > 2000)\n",
    "lengths = np.array([[k, sum(1 for _ in i)] for k, i in it.groupby(cc)])\n",
    "print(lengths)\n",
    "#plt.plot(cc*1.0)\n",
    "\n",
    "lengths[lengths[:,1]<2000,0] = 0\n",
    "keepers = np.repeat(lengths[:,0], lengths[:,1])\n",
    "#plt.plot(keepers*1.0)\n",
    "#plt.show()\n",
    "\n",
    "plt.plot(sigProc.pos )\n",
    "plt.title(\"position with amplitude drawn\")\n",
    "bb2 = np.array(np.where(keepers)).flatten()\n",
    "\n",
    "plt.plot(bb2, sigProc.pos[bb2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb2 = np.array(np.where(keepers)).flatten()\n",
    "plt.plot(bb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(aa)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# refref: here here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to understand rolling variance\n",
    "xx = np.arange(0, 20000)\n",
    "\n",
    "yy =  0.011*xx *np.random.randn(len(xx))#3*np.sin(2*np.pi * xx/500)* np.sin(xx/3000)\n",
    "\n",
    "xx\n",
    "plt.plot(xx, yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accMxs = pd.Series(yy).rolling(int(5000), center = True, min_periods = 1).var().tolist()\n",
    "# plt.plot(abs(sigProc.filtered_acc -np.mean(sigProc.filtered_acc)))\n",
    "\n",
    "plt.scatter(xx, yy, s = 1)\n",
    "plt.plot(accMxs, c= 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist(x): # same as L2 Norm\n",
    "    return x.dot(x)/len(x)\n",
    "\n",
    "#yy = 3*np.sin(2*np.pi * xx/500)* np.sin(xx/3000)\n",
    "accMxs = pd.Series(yy).rolling(int(2000), center = True, min_periods = 1).apply(euclidean_dist).tolist()\n",
    "# plt.plot(abs(sigProc.filtered_acc -np.mean(sigProc.filtered_acc)))\n",
    "\n",
    "plt.scatter(xx, yy, s = 1)\n",
    "plt.plot(accMxs, c= 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "20000 / 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def varNoMean(x):\n",
    "    return np.sum((x)**2)/len(x)\n",
    "\n",
    "#yy = 3*np.sin(2*np.pi * xx/500)* np.sin(xx/3000)\n",
    "accMxs = pd.Series(yy).rolling(int(500), center = True, min_periods = 1).apply(varNoMean).tolist()\n",
    "# plt.plot(abs(sigProc.filtered_acc -np.mean(sigProc.filtered_acc)))\n",
    "\n",
    "plt.scatter(xx, yy, s = 1)\n",
    "plt.plot(accMxs, c= 'r')\n",
    "plt.show()\n",
    "\n",
    "accMxs = pd.Series(yy).rolling(int(500), center = True, min_periods = 1).var().tolist()\n",
    "# plt.plot(abs(sigProc.filtered_acc -np.mean(sigProc.filtered_acc)))\n",
    "\n",
    "plt.scatter(xx, yy, s = 1)\n",
    "plt.plot(accMxs, c= 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum((xx - np.mean(xx))**2)/len(xx)\n",
    "np.var(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# why does position sometimes have a slope?  does it depend on phase? \n",
    "bb.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newSig = np.concatenate([np.flip(sigProc.sigl[0:5000], axis = 0),sigProc.sigl, sigProc.sigl[15000:len(sigProc.sigl)]])\n",
    "plt.plot(newSig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for foldNum in range(len(allFolders)):\n",
    "    tmpF = os.path.join(dd, allFolders[foldNum])\n",
    "    tmpDF = pd.read_csv(tmpF, header = None)\n",
    "    tmpDF.columns = [\"frq\", \"MaxMinAmp\", \"fname_short\", \"dd\", \"TT\", \"AA\", \"BB\"]\n",
    "    tmpDF.fname_short = [ff.strip() for ff in tmpDF.fname_short]\n",
    "\n",
    "\n",
    "\n",
    "    fold = os.path.join(dd, allFolders[foldNum]).split(\"_ampFreq.txt\")[0]\n",
    "\n",
    "    accRecs = [f for f in os.listdir(fold) if not f.startswith(\".\") ]\n",
    "\n",
    "\n",
    "\n",
    "    for ii in range(len(accRecs)):\n",
    "        # read in data\n",
    "        ar = accRecs[ii]\n",
    "        tmpdf1 = readMyFile(os.path.join(fold, ar))\n",
    "\n",
    "        # compute fft and save\n",
    "        fft = fft_()\n",
    "\n",
    "        # convert signal to m/s/s (*1000 / 10.17)\n",
    "        fft.fit(timesteps = tmpdf1.iloc[:,0 ], signal = np.array(tmpdf1.iloc[:,1]*1000 / 10.17))\n",
    "        #print(fft.dominant_freq, fft.max_amp)\n",
    "\n",
    "        if ii == 0:\n",
    "            tmpDF2 = np.hstack([ar, fft.dominant_freq, fft.max_amp[0], fft.amp_pos])\n",
    "\n",
    "        else:\n",
    "            tmpDF2 = np.vstack([tmpDF2, np.hstack([ar, int(fft.dominant_freq), fft.max_amp[0], fft.amp_pos])])\n",
    "        \n",
    "        #print(fft.dominant_freq)\n",
    "        #fft.plot_fft()\n",
    "\n",
    "    tmpDF2 = pd.DataFrame(tmpDF2)\n",
    "    tmpDF2.columns = [\"filename\", \"freq\", \"acc_amplitude_fft\", \"pos_amplitude_fft\" ]\n",
    "    tmpDF2.sort_values(by = \"filename\", inplace = True)\n",
    "    tmpDF2.reset_index(inplace = True, drop = True)\n",
    "    tmpDF2[\"fname_short\"] = [\"_\".join(tmpDF2.filename[jj].split(\"_\")[0:8]) for jj in range(len(tmpDF2))]\n",
    "\n",
    "\n",
    "    tmpDF3 = pd.merge(tmpDF2, tmpDF, how = \"outer\", left_on = \"fname_short\", right_on = \"fname_short\")\n",
    "    tmpDF3[\"Folder\"] = fold.split(\"/\")[-2]\n",
    "\n",
    "    if(foldNum == 0):\n",
    "        bigDF = pd.DataFrame(tmpDF3) \n",
    "    else:\n",
    "        bigDF = pd.concat([bigDF, tmpDF3])\n",
    "    \n",
    "    print(foldNum)\n",
    "\n",
    "bigDF.reset_index(drop = True, inplace = True)\n",
    "bigDF.freq = pd.to_numeric(bigDF.freq)\n",
    "bigDF.acc_amplitude_fft = pd.to_numeric(bigDF.acc_amplitude_fft)\n",
    "bigDF.pos_amplitude_fft = pd.to_numeric(bigDF.pos_amplitude_fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for foldNum in range(len(allFolders)):\n",
    "    tmpF = os.path.join(dd, allFolders[foldNum])\n",
    "    tmpDF = pd.read_csv(tmpF, header = None)\n",
    "    tmpDF.columns = [\"frq\", \"MaxMinAmp\", \"fname_short\", \"dd\", \"TT\", \"AA\", \"BB\"]\n",
    "    tmpDF.fname_short = [ff.strip() for ff in tmpDF.fname_short]\n",
    "\n",
    "\n",
    "\n",
    "    fold = os.path.join(dd, allFolders[foldNum]).split(\"_ampFreq.txt\")[0]\n",
    "\n",
    "    accRecs = [f for f in os.listdir(fold) if not f.startswith(\".\") ]\n",
    "\n",
    "\n",
    "\n",
    "    for ii in range(len(accRecs)):\n",
    "        # read in data\n",
    "        ar = accRecs[ii]\n",
    "        tmpdf1 = readMyFile(os.path.join(fold, ar))\n",
    "\n",
    "        # compute fft and save\n",
    "        fft = fft_()\n",
    "\n",
    "        # convert signal to m/s/s (*1000 / 10.17)\n",
    "        fft.fit(timesteps = tmpdf1.iloc[:,0 ], signal = np.array(tmpdf1.iloc[:,1]*1000 / 10.17))\n",
    "        #print(fft.dominant_freq, fft.max_amp)\n",
    "\n",
    "        if ii == 0:\n",
    "            tmpDF2 = np.hstack([ar, fft.dominant_freq, fft.max_amp[0], fft.amp_pos])\n",
    "\n",
    "        else:\n",
    "            tmpDF2 = np.vstack([tmpDF2, np.hstack([ar, int(fft.dominant_freq), fft.max_amp[0], fft.amp_pos])])\n",
    "        \n",
    "        #print(fft.dominant_freq)\n",
    "        #fft.plot_fft()\n",
    "\n",
    "    tmpDF2 = pd.DataFrame(tmpDF2)\n",
    "    tmpDF2.columns = [\"filename\", \"freq\", \"acc_amplitude_fft\", \"pos_amplitude_fft\" ]\n",
    "    tmpDF2.sort_values(by = \"filename\", inplace = True)\n",
    "    tmpDF2.reset_index(inplace = True, drop = True)\n",
    "    tmpDF2[\"fname_short\"] = [\"_\".join(tmpDF2.filename[jj].split(\"_\")[0:8]) for jj in range(len(tmpDF2))]\n",
    "\n",
    "\n",
    "    tmpDF3 = pd.merge(tmpDF2, tmpDF, how = \"outer\", left_on = \"fname_short\", right_on = \"fname_short\")\n",
    "    tmpDF3[\"Folder\"] = fold.split(\"/\")[-2]\n",
    "\n",
    "    if(foldNum == 0):\n",
    "        bigDF = pd.DataFrame(tmpDF3) \n",
    "    else:\n",
    "        bigDF = pd.concat([bigDF, tmpDF3])\n",
    "    \n",
    "    print(foldNum)\n",
    "\n",
    "bigDF.reset_index(drop = True, inplace = True)\n",
    "bigDF.freq = pd.to_numeric(bigDF.freq)\n",
    "bigDF.acc_amplitude_fft = pd.to_numeric(bigDF.acc_amplitude_fft)\n",
    "bigDF.pos_amplitude_fft = pd.to_numeric(bigDF.pos_amplitude_fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigM = []\n",
    "\n",
    "for foldNum in  range(len(allFolders)):\n",
    "    tmpF = os.path.join(dd, allFolders[foldNum])\n",
    "    tmpDF = pd.read_csv(tmpF, header = None)\n",
    "    tmpDF.columns = [\"frq\", \"MaxMinAmp\", \"fname_short\", \"dd\", \"TT\", \"AA\", \"BB\"]\n",
    "    tmpDF.fname_short = [ff.strip() for ff in tmpDF.fname_short]\n",
    "\n",
    "\n",
    "\n",
    "    fold = os.path.join(dd, allFolders[foldNum]).split(\"_ampFreq.txt\")[0]\n",
    "\n",
    "    accRecs = [f for f in os.listdir(fold) if not f.startswith(\".\") ]\n",
    "\n",
    "    mm = []\n",
    "\n",
    "    for ii in range(len(accRecs)):\n",
    "            # read in data\n",
    "            ar = accRecs[ii]\n",
    "            tmpdf1 = readMyFile(os.path.join(fold, ar))\n",
    "            signal = (tmpdf1.iloc[:,1] - np.mean(tmpdf1.iloc[:,1]))*1000 / 10.17\n",
    "            times = tmpdf1.iloc[:,0]\n",
    "            mxs = pd.Series(abs(signal)).rolling(int(tmpdf1.shape[0]/28), center = True, min_periods = 1).max().tolist()\n",
    "\n",
    "            mm.append(np.unique(mxs))\n",
    "\n",
    "    out = np.concatenate(mm).ravel()\n",
    "    bigM.append(out)\n",
    "    print(foldNum)\n",
    "    #plt.hist(out[out <10], bins = 30, density = True)\n",
    "    #plt.xlim(0, 10)\n",
    "    sns.kdeplot(np.array(out[out <15]), bw=0.3)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "zz = np.concatenate(bigM).ravel()\n",
    "plt.hist(zz[zz < 20], density = True, bins = 200)\n",
    "sns.kdeplot(zz[zz < 20], bw=0.2)\n",
    "plt.xlim(0, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "       \n",
    "\n",
    "\n",
    "ii =0\n",
    "ar = accRecs[ii]\n",
    "tmpdf1 = readMyFile(os.path.join(fold, ar))\n",
    "\n",
    "signal = (tmpdf1.iloc[:,1] - np.mean(tmpdf1.iloc[:,1]))*1000 / 10.17\n",
    "times = tmpdf1.iloc[:,0]\n",
    "mxs = pd.Series(abs(signal)).rolling(int(tmpdf1.shape[0]/28), center = True, min_periods = 1).max().tolist()\n",
    "print(int(tmpdf1.shape[0]/28))\n",
    "plt.plot(abs(signal))\n",
    "plt.plot(mxs)\n",
    "plt.show()\n",
    "\n",
    "plt.hist(mxs)\n",
    "plt.show()\n",
    "\n",
    "t2 = times[np.array(mxs) > 2.0]\n",
    "s2 = signal[np.array(mxs) > 2.0]\n",
    "\n",
    "fft = fft_()\n",
    "fft.fit(t2, s2)\n",
    "fft.plot_fft()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(np.mod(times, 0.01) > 0.005) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sig1_amp = np.round(np.mod(times, 0.01), decimals = 1)\n",
    "\n",
    "\n",
    "signal = (np.mod(times, 0.01) > 0.005)*np.sin(2* np.pi * (times* 200)) #+ 0.2*np.random.randn(len(times))\n",
    "signal[abs(signal)>0.9] = 2*np.sin(2* np.pi * (times[abs(signal)>0.9]* 200))\n",
    "\n",
    "signal = signal + ~(np.mod(times, 0.01) > 0.005)*np.sin(2* np.pi * times* 1000)*0.1 #+ np.sin(2* np.pi * (times* 3))\n",
    "\n",
    "\n",
    "#signal = np.sin(2* np.pi * (times* 100))\n",
    "#signal[times < 0.07] = np.sin(2* np.pi * times* 1000)*0.1\n",
    "\n",
    "\n",
    "#signal = 0.8*np.sin(2* np.pi * times* 400) + np.sin(2* np.pi * (times* 200 + 400))\n",
    "\n",
    "\n",
    "#sig1 = np.sin(2* np.pi * times* 50)\n",
    "\n",
    "\n",
    "#signal = 5.44 * np.sin(2* np.pi * times* 200) + 4 * np.sin(2* np.pi * times* 400)\n",
    "\n",
    "#signal = lowess(signal + 0.01*np.random.randn(len(times)), times, frac = 1/20)[:,1]\n",
    "plt.figure(figsize = [10,10])\n",
    "plt.plot(signal)\n",
    "#plt.hlines(xmin = 0, xmax = 20000, y = 0.54)\n",
    "\n",
    "fft = fft_()\n",
    "fft.fit(times, signal)\n",
    "fft.plot_fft()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "\n",
    "def highpass_filter(y, sr):\n",
    "    filter_stop_freq = 70  # Hz\n",
    "    filter_pass_freq = 100  # Hz\n",
    "    filter_order = 1001\n",
    "\n",
    "    # High-pass filter\n",
    "    nyquist_rate = sr / 2.\n",
    "    desired = (0, 0, 1, 1)\n",
    "    bands = (0, filter_stop_freq, filter_pass_freq, nyquist_rate)\n",
    "    filter_coefs = signal.firls(filter_order, bands, desired, nyq=nyquist_rate)\n",
    "\n",
    "    # Apply high-pass filter\n",
    "    filtered_audio = signal.filtfilt(filter_coefs, [1], y)\n",
    "    return filtered_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc = 0.1\n",
    "b = 0.08\n",
    "N = int(np.ceil((4 / b)))\n",
    "if not N % 2: N += 1\n",
    "n = np.arange(N)\n",
    " \n",
    "sinc_func = np.sinc(2 * fc * (n - (N - 1) / 2.))\n",
    "window = np.blackman(N)\n",
    "sinc_func = sinc_func * window\n",
    "sinc_func = sinc_func / np.sum(sinc_func)\n",
    "\n",
    "# reverse function\n",
    "sinc_func = -sinc_func\n",
    "sinc_func[(N - 1) / 2] += 1\n",
    "\n",
    "s = list(data['10 Min Std Dev'])\n",
    "new_signal = np.convolve(s, sinc_func)\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    x=range(len(new_signal)),\n",
    "    y=new_signal,\n",
    "    mode='lines',\n",
    "    name='High-Pass Filter',\n",
    "    marker=dict(\n",
    "        color='#424242'\n",
    "    )\n",
    ")\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='High-Pass Filter',\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "trace_data = [trace1]\n",
    "fig = go.Figure(data=trace_data, layout=layout)\n",
    "py.iplot(fig, filename='fft-high-pass-filter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "def sine_generator(timesteps, sinefreq):\n",
    "    nsamples = len(timesteps)\n",
    "    w = 2. * np.pi * sinefreq\n",
    "    y_sine = np.sin(w * timesteps)*3.22\n",
    "    result = pd.DataFrame({ \n",
    "        'data' : y_sine} ,index=timesteps)\n",
    "    return result\n",
    "\n",
    "def butter_highpass(cutoff, log_rate, order=5):\n",
    "    nyq = 0.5 * log_rate\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = signal.butter(order, normal_cutoff, btype='high', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def butter_highpass_filter(data, cutoff, log_rate, order=5):\n",
    "    b, a = butter_highpass(cutoff, log_rate, order=order)\n",
    "    y = signal.filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "\n",
    "timesteps = np.linspace(0, 0.1, num = 20000)\n",
    "log_rate = 200000 # samples per second\n",
    "sine_fq = 300\n",
    "\n",
    "sine_5Hz = sine_generator(timesteps,sine_fq)\n",
    "sine_fq = 30 #Hz\n",
    "sine_1Hz = sine_generator(timesteps,sine_fq)\n",
    "sine = sine_5Hz + sine_1Hz\n",
    "plt.plot(sine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sine = sine_5Hz + sine_1Hz\n",
    "sig1_amp = np.round(np.mod(timesteps, 0.01), decimals = 1)\n",
    "\n",
    "\n",
    "sig = (np.mod(timesteps, 0.01) > 0.005*3/2)*np.sin(2* np.pi * (timesteps* 300)) #+ 0.2*np.random.randn(len(times))\n",
    "sig[abs(sig)>0.9] = 2*np.sin(2* np.pi * (timesteps[abs(sig)>0.9]* 300))\n",
    "\n",
    "sig = sig + ~(np.mod(timesteps, 0.01) > 0.005)*np.sin(2* np.pi * timesteps* 1000)* 0.1 + np.sin(2* np.pi * (timesteps* 10))\n",
    "sine['data'] = data\n",
    "#sine['data'] = sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sine = butter_highpass_filter(sine.data, 200, log_rate)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(211)\n",
    "plt.plot(sine)\n",
    "plt.title('generated signal')\n",
    "plt.subplot(212)\n",
    "plt.plot(range(len(filtered_sine)),filtered_sine)\n",
    "plt.title('filtered signal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vel = np.cumsum(filtered_sine)/log_rate\n",
    "\n",
    "pos = np.cumsum(vel - np.mean(vel)) / log_rate\n",
    "\n",
    "aa = fft_()\n",
    "aa.fit(timesteps, pos-np.mean(pos))\n",
    "plt.figure(figsize = [15,10])\n",
    "plt.plot(timesteps, pos - np.mean(pos))\n",
    "plt.hlines(xmin = 0, xmax = 0.01, y = [aa.max_amp, 1.8e-06])\n",
    "aa.plot_fft()\n",
    "print(aa.max_amp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fft = fft_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fft.fit(timesteps, filtered_sine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft.plot_fft()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peakind = signal.find_peaks_cwt(filtered_sine, widths = np.arange(200, 400))\n",
    "plt.plot(timesteps,filtered_sine)\n",
    "plt.scatter(timesteps[peakind], np.array(filtered_sine)[peakind], c= 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " np.array(sine.data)[peakind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "t = timesteps \n",
    "t= np.linspace(-1, 1, 200, endpoint=False)\n",
    "sig  = sine.data\n",
    "# filtered_sine \n",
    "#sig = np.cos(2 * np.pi * 7 * t) + signal.gausspulse(t - 0.4, fc=2)\n",
    "widths = np.arange(1000, 2000)\n",
    "cwtmatr = signal.cwt(sig, signal.ricker, widths)\n",
    "plt.plot(sig)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(cwtmatr, extent=[-1, 1, 1, 31], cmap='PRGn', aspect='auto',\n",
    "           vmax=abs(cwtmatr).max(), vmin=-abs(cwtmatr).max())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# analytical calculate position amplitude\n",
    "2.0 / (np.pi * 2 * 100)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(fft.frq,abs(fft.Y))\n",
    "print(fft.amp_pos)\n",
    "plt.xlim(0, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vel = np.cumsum(signal)/log_rate\n",
    "\n",
    "pos = np.cumsum(vel - np.mean(vel)) / log_rate\n",
    "\n",
    "aa = fft_()\n",
    "aa.fit(times, pos-np.mean(pos))\n",
    "plt.figure(figsize = [15,10])\n",
    "plt.plot(times, pos - np.mean(pos))\n",
    "plt.hlines(xmin = 0, xmax = 0.01, y = [aa.max_amp, 1.8e-06])\n",
    "aa.plot_fft()\n",
    "print(aa.max_amp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v2 = np.diff(pos) *log_rate\n",
    "a2 = np.diff(v2-np.mean(v2)) * log_rate\n",
    "plt.figure(figsize = [15,10])\n",
    "\n",
    "plt.plot(pos-np.mean(pos))\n",
    "plt.show()\n",
    "\n",
    "plt.plot(v2-np.mean(v2))\n",
    "plt.show()\n",
    "plt.plot(a2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pdvega  # import adds vgplot attribute to pandas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sig1 = np.sin(2* np.pi * times* 350)\n",
    "\n",
    "\n",
    "signal = 5*np.sin(2* np.pi * times* 352)\n",
    "signal[abs(sig1) < 0.99] =  sig1\n",
    "\n",
    "#signal[signal < 0] =  signal[signal < 0]*5\n",
    "signal = signal + np.random.randn(len(times))*0.4\n",
    "\n",
    "signal.vgplot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ii +=1\n",
    "ar = accRecs[ii]\n",
    "tmpdf1 = readMyFile(os.path.join(fold, ar))\n",
    "\n",
    "signal = (tmpdf1.iloc[:,1] - np.mean(tmpdf1.iloc[:,1]))*1000 / 10.17\n",
    "times = tmpdf1.iloc[:,0]\n",
    "mxs = pd.Series(abs(signal)).rolling(int(tmpdf1.shape[0]/28), center = True, min_periods = 1).max().tolist()\n",
    "print(int(tmpdf1.shape[0]/28))\n",
    "plt.plot(abs(signal))\n",
    "plt.plot(mxs)\n",
    "\n",
    "plt.show()\n",
    "plt.plot(signal)\n",
    "plt.show()\n",
    "plt.plot(signal[0:5000])\n",
    "\n",
    "\n",
    "\n",
    "signal[0:5000].vgplot.line()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fft = fft_()\n",
    "fft.fit(times, signal-np.mean(signal))\n",
    "fft.plot_fft()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sig1 = np.sin(2* np.pi * times* 50)\n",
    "\n",
    "\n",
    "signal = 5.44 * np.sin(2* np.pi * times* 200) + 4 * np.sin(2* np.pi * times* 400)\n",
    "plt.plot(signal)\n",
    "\n",
    "fft = fft_()\n",
    "fft.fit(times, signal)\n",
    "fft.plot_fft()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(bigDF.shape)\n",
    "bigDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(hl.shape)\n",
    "hl.datetime = [ff.strip() for ff in hl.datetime]\n",
    "hl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge bigDF and hl\n",
    "\n",
    "totalDF = pd.merge(bigDF, hl, left_on = [\"fname_short\", \"freq\"], right_on=[\"datetime\", \"freq\"], how = \"inner\")\n",
    "totalDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "totalDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change column names\n",
    "totalDF2 =totalDF.rename(columns = {'amp_acc':'MinMax_amp_acc_m/s/s', \n",
    "                                    'amp': 'MinMax_amp_Volts', \n",
    "                                   'acc_amplitude_fft': 'acc_amplitude_fft_m/s/s', \n",
    "                                    'pos_amplitude_fft': 'pos_amplitude_fft_m'\n",
    "                                   })\n",
    "totalDF2.drop([\"frq\", \"TT\", \"AA\", \"BB\", \"dd\", \"fname_short\", \"MaxMinAmp\"], axis = 1, inplace = True)\n",
    "totalDF2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(x = totalDF2['acc_amplitude_fft_m/s/s'], y = totalDF2['pos_amplitude_fft_m']*10**7, s= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write to file\n",
    "totalDF2.to_csv(\"/Users/cswitzer/Dropbox/SonicationBehavior/SonBehData/02_1_HeavyLight_cleaned_posAdded.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(x = totalDF2.MinMax_amp_Volts, y = totalDF2['acc_amplitude_fft_m/s/s'], s = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ar = accRecs[2]\n",
    "stt = time.time()\n",
    "dta = readMyFile(os.path.join(fold, ar))\n",
    "\n",
    "\n",
    "#fft practice\n",
    "\n",
    "#xx = np.linspace(0, 0.1, num = 1000)\n",
    "#act = 2.09906008*np.sin(350*2*np.pi*xx) \n",
    "xx = dta.iloc[:,0 ]\n",
    "act = dta.iloc[:,1]*1000 / 10.17\n",
    "\n",
    "#plt.plot(xx, act)\n",
    "\n",
    "log_rate = len(xx)*(1/(np.max(xx)))\n",
    "\n",
    "n =len(act) # length of the signal\n",
    "k = np.arange(n, step = 1)\n",
    "T = n/log_rate\n",
    "frq = k/T # two sides frequency range\n",
    "frq = frq[range(int(n/2))] # one side frequency range\n",
    "\n",
    "\n",
    "# fft computing and normalization (note that *2 is so that it is scaled properly)\n",
    "Y = np.fft.fft(act)/n *2 \n",
    "Y = Y[range(int(n/2))]\n",
    "\n",
    "# calculate top frequency\n",
    "ind = np.argpartition(abs(Y), -4)[-4:]\n",
    "# Find highest point on the spectrum\n",
    "peakFrq = frq[ind[::-1]]\n",
    "pwr = (abs(Y)[ind[::-1]])\n",
    "domPK = [x for (y,x) in sorted(zip(pwr,peakFrq), reverse = True)][0]\n",
    "\n",
    "beeFrqPwr = pwr[peakFrq == domPK]\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "gs = gridspec.GridSpec(1, 2, width_ratios=[2,2]) \n",
    "\n",
    "#create subplot 1\n",
    "ax1 = plt.subplot(gs[0])\n",
    "\n",
    "ax1.plot(xx,act,color = 'black', linewidth=0.5 )\n",
    "\n",
    "ax2 = plt.subplot(gs[1])\n",
    "ax2.plot(frq,abs(Y), color = \"black\", linewidth=0.5)\n",
    "ax2.plot(domPK, beeFrqPwr,'o', color = 'black', markersize = 5)\n",
    "\n",
    "ax2.set_xlim(-0, 1003)\n",
    "print(beeFrqPwr)\n",
    "\n",
    "print(time.time() - stt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# processing -- find signal envelope\n",
    "\n",
    "from scipy.signal import hilbert\n",
    "duration = 0.1\n",
    "fs = log_rate/2\n",
    "samples = int(fs*duration)\n",
    "t = np.arange(samples) / fs\n",
    "\n",
    "signal = act\n",
    "#signal *= (1.0 + 0.5 * np.sin(2.0*np.pi*3.0*t) )\n",
    "\n",
    "analytic_signal = hilbert(signal)\n",
    "amplitude_envelope = np.abs(analytic_signal)\n",
    "instantaneous_phase = np.unwrap(np.angle(analytic_signal))\n",
    "#instantaneous_frequency = (np.diff(instantaneous_phase) /\n",
    "#                           (2.0*np.pi) * fs)\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax0 = fig.add_subplot(211)\n",
    "ax0.plot(t, signal, label='signal')\n",
    "ax0.plot(t, amplitude_envelope, label='envelope')\n",
    "ax0.set_xlabel(\"time in seconds\")\n",
    "ax0.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recDir = os.listdir(\"/Users/cswitzer/Dropbox/SonicationBehavior/SonBehData/SonicationBehavior_HeavyLight/Bee31_19Oct2016_Hive3_W_S/2016_10_19__11_23_02\")\n",
    "recDir = [ii for ii in recDir if not ii.startswith(\".\")]\n",
    "\n",
    "print(len(recDir))\n",
    "dct = \"/Users/cswitzer/Dropbox/SonicationBehavior/SonBehData/SonicationBehavior_HeavyLight/Bee31_19Oct2016_Hive3_W_S/2016_10_19__11_23_02\"\n",
    "f = recDir[0]\n",
    "\n",
    "# load in all data\n",
    "def readCenter(f):\n",
    "    tmp = np.transpose(pd.read_csv(os.path.join(dct, f), sep = \" \", header = None))\n",
    "    tmp.iloc[:,1] = tmp.iloc[:,1] - np.mean(tmp.iloc[:,1])\n",
    "    tmp[\"name\"] = f\n",
    "    print(f)\n",
    "    return(tmp)\n",
    "\n",
    "df = pd.concat( [readCenter(f) for f in recDir] )\n",
    "#np.transpose(pd.read_csv(os.path.join(dct, f), sep = \" \", header = None))\n",
    "#combined_csv = \n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "direct = \"/Users/cswitzer/Dropbox/SonicationBehavior/SonBehData/SonicationBehavior_HeavyLight/Bee2_27Sept_Hive4_S_W/2016_09_27__11_54_44\"\n",
    "\n",
    "recDir = os.listdir(direct)\n",
    "recDir = [ii for ii in recDir if not ii.startswith(\".\")]\n",
    "\n",
    "print(len(recDir))\n",
    "dct = direct\n",
    "f = recDir[0]\n",
    "\n",
    "# load in all data\n",
    "def readCenter(f):\n",
    "    tmp = np.transpose(pd.read_csv(os.path.join(dct, f), sep = \" \", header = None))\n",
    "    tmp.iloc[:,1] = tmp.iloc[:,1] - np.mean(tmp.iloc[:,1])\n",
    "    tmp[\"name\"] = f\n",
    "    print(f)\n",
    "    return(tmp)\n",
    "\n",
    "df = pd.concat( [readCenter(f) for f in recDir] )\n",
    "#np.transpose(pd.read_csv(os.path.join(dct, f), sep = \" \", header = None))\n",
    "#combined_csv = \n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate running mean and look at histogram\n",
    "d2 = df\n",
    "\n",
    "signal = np.array(d2.iloc[:,1]*1000 / 10.17) # convert from V to m/s/s\n",
    "act = signal\n",
    "times = d2.iloc[:,0]\n",
    "xx = times\n",
    "\n",
    "\n",
    "f, ax1 = plt.subplots()\n",
    "f.set_figwidth(15)\n",
    "ax1.plot( abs(signal),color = 'black', linewidth=0.5 )\n",
    "#ax1.scatter(xs[peakind], data[peakind])\n",
    "mxs = pd.Series(abs(signal)).rolling(int(d2.shape[0]/28/124), center = True, min_periods = 1).max().tolist()\n",
    "print(int(d2.shape[0]/28))\n",
    "ax1.plot(mxs)\n",
    "plt.show()\n",
    "\n",
    "plt.hist(np.array(mxs)[~np.isnan(np.array(mxs))], bins = 50)\n",
    "plt.vlines(ymin = 0, ymax = 175000, x = 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(mxs[0:20000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dct = direct\n",
    "recDir = os.listdir(direct)\n",
    "recDir = [ii for ii in recDir if not ii.startswith(\".\")]\n",
    "fle = os.path.join(dct, recDir[ff])\n",
    "ff+=1\n",
    "\n",
    "d2 = np.transpose(pd.read_csv(fle, sep = \" \", header = None))\n",
    "\n",
    "signal = d2.iloc[:,1]*1000 / 10.17 # convert from V to m/s/s\n",
    "act = signal-np.mean(signal)\n",
    "times = d2.iloc[:,0]\n",
    "xx = times\n",
    "\n",
    "log_rate = 200000.0\n",
    "\n",
    "n =len(act) # length of the signal\n",
    "k = np.arange(n, step = 1)\n",
    "T = n/log_rate\n",
    "frq = k/T # two sides frequency range\n",
    "frq = frq[range(int(n/2))] # one side frequency range\n",
    "\n",
    "Y = np.fft.fft(act)/n # fft computing and normalization\n",
    "Y = Y[range(int(n/2))]*2\n",
    "\n",
    "# calculate top frequency\n",
    "ind = np.argpartition(abs(Y), -4)[-4:]\n",
    "# Find highest point on the spectrum\n",
    "peakFrq = frq[ind[::-1]]\n",
    "pwr = (abs(Y)[ind[::-1]])\n",
    "domPK = [x for (y,x) in sorted(zip(pwr,peakFrq), reverse = True)][0]\n",
    "\n",
    "beeFrqPwr = pwr[peakFrq == domPK]\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "gs = gridspec.GridSpec(1, 2, width_ratios=[2,2]) \n",
    "\n",
    "# create subplot 1\n",
    "ax1 = plt.subplot(gs[0])\n",
    "\n",
    "ax1.plot(xx,act,color = 'black', linewidth=0.5 )\n",
    "\n",
    "ax2 = plt.subplot(gs[1])\n",
    "ax2.plot(frq,abs(Y), color = \"black\", linewidth=0.5)\n",
    "ax2.plot(domPK, beeFrqPwr,'o', color = 'black', markersize = 5)\n",
    "\n",
    "ax2.set_xlim(-3, 1003)\n",
    "print(beeFrqPwr)\n",
    "\n",
    "\n",
    "#plt.plot(d2.iloc[:,0], d2.iloc[:,1])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "f, ax1 = plt.subplots()\n",
    "f.set_figwidth(15)\n",
    "ax1.plot(times, abs(signal),color = 'black', linewidth=0.5 )\n",
    "#ax1.scatter(xs[peakind], data[peakind])\n",
    "mxs = pd.Series(abs(signal)).rolling(int(d2.shape[0]/28), center = True, min_periods = 1).max().tolist()\n",
    "print(int(d2.shape[0]/28))\n",
    "ax1.plot(times, mxs)\n",
    "\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "\n",
    "\n",
    "ssmp = np.array((np.linspace(0, len(mxs), num = 100) - 1).astype(int))\n",
    "smth = lowess(endog = np.array(mxs)[ssmp], exog = np.array(times)[ssmp], frac = 0.06)\n",
    "ax1.plot(times[ssmp], smth[:,1])\n",
    "plt.show()\n",
    "plt.hist(np.array(mxs)[~np.isnan(np.array(mxs))])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#________________________\n",
    "# calculate fft for subset of data\n",
    "\n",
    "df3 = d2.iloc[np.array(mxs) > 1.5, :].reset_index(drop=True)\n",
    "signal = df3.iloc[:,1]*1000 / 10.17\n",
    "act = signal-np.mean(signal)\n",
    "times = df3.iloc[:,0]\n",
    "xx = times\n",
    "\n",
    "log_rate = 200000.0\n",
    "\n",
    "n =len(act) # length of the signal\n",
    "k = np.arange(n, step = 1)\n",
    "T = n/log_rate\n",
    "frq = k/T # two sides frequency range\n",
    "frq = frq[range(int(n/2))] # one side frequency range\n",
    "\n",
    "Y = np.fft.fft(act)/n # fft computing and normalization\n",
    "Y = Y[range(int(n/2))]*2\n",
    "\n",
    "# calculate top frequency\n",
    "ind = np.argpartition(abs(Y), -4)[-4:]\n",
    "# Find highest point on the spectrum\n",
    "peakFrq = frq[ind[::-1]]\n",
    "pwr = (abs(Y)[ind[::-1]])\n",
    "domPK = [x for (y,x) in sorted(zip(pwr,peakFrq), reverse = True)][0]\n",
    "\n",
    "beeFrqPwr = pwr[peakFrq == domPK]\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "gs = gridspec.GridSpec(1, 2, width_ratios=[2,2]) \n",
    "\n",
    "# create subplot 1\n",
    "ax1 = plt.subplot(gs[0])\n",
    "\n",
    "ax1.plot(xx,act,color = 'black', linewidth=0.5 )\n",
    "\n",
    "ax2 = plt.subplot(gs[1])\n",
    "ax2.plot(frq,abs(Y), color = \"black\", linewidth=0.5)\n",
    "ax2.plot(domPK, beeFrqPwr,'o', color = 'black', markersize = 5)\n",
    "\n",
    "ax2.set_xlim(-3, 1003)\n",
    "print(beeFrqPwr)\n",
    "\n",
    "\n",
    "#plt.plot(d2.iloc[:,0], d2.iloc[:,1])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "f, ax1 = plt.subplots()\n",
    "f.set_figwidth(15)\n",
    "ax1.plot(abs(signal),color = 'black', linewidth=0.5 )\n",
    "#ax1.scatter(xs[peakind], data[peakind])\n",
    "mxs = pd.Series(abs(signal)).rolling(int(d2.shape[0]/28), center = True).max().tolist()\n",
    "print(int(d2.shape[0]/28))\n",
    "ax1.plot(np.array(mxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(smth[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print system info\n",
    "import IPython\n",
    "print(IPython.sys_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert to html, so ppl don't have to run python to see code\n",
    "!jupyter nbconvert --to html 008_ExampleFigureSpectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
