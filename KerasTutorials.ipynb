{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dim = 16\n",
    "timesteps = 8\n",
    "num_classes = 3\n",
    "\n",
    "# expected input data shape: (batch_size, timesteps, data_dim)\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True,\n",
    "               input_shape=(timesteps, data_dim)))  # returns a sequence of vectors of dimension 32\n",
    "model.add(LSTM(32, return_sequences=True))  # returns a sequence of vectors of dimension 32\n",
    "model.add(LSTM(32))  # return a single vector of dimension 32\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Generate dummy training data\n",
    "import pandas as pd  \n",
    "from random import random\n",
    "\n",
    "flow = (list(range(1,10,1)) + list(range(10,1,-1)))*1000  \n",
    "pdata = pd.DataFrame({\"a\":flow, \"b\":flow})  \n",
    "pdata.b = pdata.b.shift(9)  \n",
    "data = pdata.iloc[10:] * random()  # some noise  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "data_dim = 16\n",
    "timesteps = 8\n",
    "num_classes = 3\n",
    "\n",
    "# expected input data shape: (batch_size, timesteps, data_dim)\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True,\n",
    "               input_shape=(timesteps, data_dim)))  # returns a sequence of vectors of dimension 32\n",
    "model.add(LSTM(32, return_sequences=True))  # returns a sequence of vectors of dimension 32\n",
    "model.add(LSTM(32))  # return a single vector of dimension 32\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Generate dummy training data\n",
    "x_train = np.random.random((1000, timesteps, data_dim))\n",
    "y_train = np.random.random((1000, num_classes))\n",
    "\n",
    "# Generate dummy validation data\n",
    "x_val = np.random.random((100, timesteps, data_dim))\n",
    "y_val = np.random.random((100, num_classes))\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=640000, epochs=5,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "from numpy import array\n",
    "from numpy import cumsum\n",
    "\n",
    "limit = 1\n",
    "\n",
    "# create a sequence of random numbers in [0,1]\n",
    "X = np.array([random() for _ in range(10)])\n",
    "# determine the class outcome for each item in cumulative sequence\n",
    "y = np.array([0 if x < limit else 1 for x in cumsum(X)])\n",
    "\n",
    "\n",
    "# create a sequence classification instance\n",
    "def get_sequence(n_timesteps):\n",
    "    # create a sequence of random numbers in [0,1]\n",
    "    X = array([random() for _ in range(n_timesteps)])\n",
    "    # calculate cut-off value to change class values\n",
    "    limit = n_timesteps/4.0\n",
    "    # determine the class outcome for each item in cumulative sequence\n",
    "    y = array([0 if x < limit else 1 for x in cumsum(X)])\n",
    "    return X, y\n",
    "\n",
    "X, y = get_sequence(10)\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input and output data to be suitable for LSTMs\n",
    "n_timesteps = 10\n",
    "X = X.reshape(1, n_timesteps, 1)\n",
    "y = y.reshape(1, n_timesteps, 1)\n",
    "\n",
    "# create a sequence classification instance\n",
    "def get_sequence(n_timesteps):\n",
    "    # create a sequence of random numbers in [0,1]\n",
    "    X = array([random() for _ in range(n_timesteps)])\n",
    "    # calculate cut-off value to change class values\n",
    "    limit = n_timesteps/4.0\n",
    "    # determine the class outcome for each item in cumulative sequence\n",
    "    y = array([0 if x < limit else 1 for x in cumsum(X)])\n",
    "    # reshape input and output data to be suitable for LSTMs\n",
    "    X = X.reshape(1, n_timesteps, 1)\n",
    "    y = y.reshape(1, n_timesteps, 1)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TimeDistributed\n",
    "\n",
    "# define LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(20, input_shape=(10, 1), return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(1, activation='sigmoid')))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def windowsOrMacDirectories():\n",
    "    \"\"\" Sets base directories for win or mac\n",
    "\n",
    "       \n",
    "    \"\"\"\n",
    "    if os.environ['COMPUTERNAME'] == 'SHEALMACLEARN':\n",
    "        DropboxDirect = os.path.join(\"D:\\Dropbox\")\n",
    "#     elif sys.platform.startswith('linux') or sys.platform.startswith('cygwin'):\n",
    "#         # this excludes your current terminal \"/dev/tty\"\n",
    "    elif sys.platform.startswith('darwin'):\n",
    "        DropboxDirect = os.path.join(\"/Users/cswitzer/Dropbox\")\n",
    "    else:\n",
    "        raise EnvironmentError('Unknown computer platform')\n",
    "    \n",
    "    baseDir = os.getcwd()\n",
    "    dataDir = os.path.join(DropboxDirect, 'SonicationBehavior', 'SonBehData')\n",
    "    figDir = os.path.join(DropboxDirect, 'SonicationBehavior', 'SonBehFigs')\n",
    "    return baseDir, dataDir, figDir\n",
    "\n",
    "\n",
    "baseDir, dataDir, figDir = windowsOrMacDirectories()\n",
    "print(dataDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def readMyFile(filename):\n",
    "    \n",
    "    '''Read in csv 10x faster than pandas'''\n",
    "    \n",
    "    tmpdta = []\n",
    " \n",
    "    with open(filename, newline=\"\\n\") as csvDataFile:\n",
    "        csvReader = csv.reader(csvDataFile, delimiter=' ', quoting=csv.QUOTE_NONNUMERIC)\n",
    "        for row in csvReader:\n",
    "            tmpdta.append(row)\n",
    " \n",
    "    return(pd.DataFrame(np.transpose(tmpdta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import seaborn as sns\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "from scipy import signal\n",
    "import itertools as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in dataset that was pre-classified\n",
    "buzzClassDataDir = os.path.join(\"D:\\Dropbox\\SonicationBehavior\\SonBehData\\BuzzPartClassification\")\n",
    "buzzClass = pd.read_csv(os.path.join(buzzClassDataDir, 'BuzzClassifications.csv'))\n",
    "print(buzzClass.shape)\n",
    "buzzClass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all data into a single dataframe\n",
    "bigList = []\n",
    "freqSpec = []\n",
    "for ii in range(buzzClass.shape[0]):\n",
    "    tmp = readMyFile(buzzClass.fileName[ii])\n",
    "    \n",
    "    # pad with 0's\n",
    "    tmp = readMyFile(buzzClass.fileName[ii])\n",
    "    pad = np.arange(tmp.iloc[-1,0],tmp.iloc[-1,0]+ 0.02 - np.mean(np.diff(tmp.iloc[:,0])),  np.mean(np.diff(tmp.iloc[:,0])))\n",
    "    zx = np.repeat(0, len(pad))\n",
    "    pdff = pd.DataFrame( data = {\"0\":pad, \"1\":zx} )\n",
    "    pdff.columns = tmp.columns\n",
    "\n",
    "    tmp = pd.concat([tmp, pdff]).reset_index(drop = True)\n",
    "    \n",
    "    # calculate rolling variance\n",
    "    tmp[\"varia\"] = pd.Series((tmp.iloc[:,1] - np.mean(tmp.iloc[:,1]))).rolling(int(2000), center = True, min_periods = 1).var().tolist()\n",
    "    \n",
    "    # calculate frequency spectrum\n",
    "    f, t, Sxx = signal.spectrogram(tmp.iloc[:,1], 200000, noverlap = 900, nperseg = 1000)\n",
    "    Sxx = Sxx[0:50, :]\n",
    "    #scale\n",
    "    Sxx = Sxx - np.min(Sxx)\n",
    "    Sxx = Sxx / np.max(Sxx)\n",
    "    \n",
    "    \n",
    "    \n",
    "    freqSpec.append(pd.DataFrame(np.transpose(Sxx)))\n",
    "    \n",
    "    # add classes to data\n",
    "    tmp[\"buzz\"] = 0\n",
    "    tmp.loc[buzzClass.buzz1[ii]:buzzClass.buzz2[ii], \"buzz\"] = 1\n",
    "    if(np.mod(ii, 10)) == 0:\n",
    "        print(ii)\n",
    "    \n",
    "    tmp[\"filename\"] = buzzClass.fileName[ii]\n",
    "    bigList.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(bigList)\n",
    "df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df.iloc[0:20000, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = MinMaxScaler((0,1))\n",
    "mm.fit(df.iloc[:, 1].values.reshape(-1, 1))\n",
    "df[\"scaledBuzz\"] = mm.transform(df.iloc[:, 1].values.reshape(-1, 1))\n",
    "\n",
    "\n",
    "subSamp = np.arange(0, 200000, step = 50)# np.arange(0, df.shape[0], step = 5)\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.scatter(df.index[subSamp], df.iloc[subSamp,5], s = 0.5, c = df.iloc[subSamp,3])\n",
    "#plt.scatter(df.index[subSamp], df.iloc[subSamp,2]*10, s = 0.5, c = df.iloc[subSamp,3])\n",
    "plt.show()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "from numpy import array\n",
    "from numpy import cumsum\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import CuDNNLSTM\n",
    "\n",
    "earlystop = EarlyStopping(monitor='loss', patience=7, verbose=1, mode='auto')\n",
    "\n",
    "# create a sequence classification instance\n",
    "def get_sequence(kk , n_timesteps):\n",
    "    # create a sequence of random numbers in [0,1]\n",
    "    X = np.array(df.iloc[(kk):((kk + n_timesteps)), 5])\n",
    "    # calculate cut-off value to change class values\n",
    "    y = np.array(df.iloc[(kk):((kk + n_timesteps)), 3])\n",
    "    # reshape input and output data to be suitable for LSTMs\n",
    "    X = X.reshape(1, n_timesteps, 1)\n",
    "    y = y.reshape(1, n_timesteps, 1)\n",
    "    return X, y\n",
    "\n",
    "# define problem properties\n",
    "n_timesteps = 100000\n",
    "# define LSTM\n",
    "model = Sequential()\n",
    "model.add(CuDNNLSTM(200, input_shape=(n_timesteps, 1), return_sequences=True))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(TimeDistributed(Dense(1, activation='sigmoid')))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# train LSTM\n",
    "\n",
    "samples = np.random.choice(range(df.shape[0]), 100, replace = False)\n",
    "\n",
    "# generate new random sequence\n",
    "X,y = get_sequence(0, n_timesteps)\n",
    "# fit model for one epoch on this sequence\n",
    "model.fit(X,y, batch_size = 10000, verbose = 1, epochs  = 100, callbacks=[earlystop])\n",
    "\n",
    "# evaluate LSTM\n",
    "X,y = get_sequence(n_timesteps, n_timesteps)\n",
    "yhat = model.predict_classes(X, verbose=0)\n",
    "for i in range(n_timesteps):\n",
    "    print('Expected:', y[0, i], 'Predicted', yhat[0, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "from numpy import array\n",
    "from numpy import cumsum\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import CuDNNLSTM\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "\n",
    "earlystop = EarlyStopping(monitor='loss', patience=70, verbose=1, mode='auto')\n",
    "\n",
    "# create a sequence classification instance\n",
    "def get_sequence(kk , n_timesteps):\n",
    "    # create a sequence of random numbers in [0,1]\n",
    "    X = np.array(df.iloc[(kk):((kk + n_timesteps)), 5])\n",
    "    # calculate cut-off value to change class values\n",
    "    y = np.array(df.iloc[(kk):((kk + n_timesteps)), 3])\n",
    "    # reshape input and output data to be suitable for LSTMs\n",
    "    X = X.reshape(1, n_timesteps, 1)\n",
    "    y = y.reshape(1, n_timesteps, 1)\n",
    "    return X, y\n",
    "\n",
    "# define problem properties\n",
    "n_timesteps = 100000\n",
    "# define LSTM\n",
    "model = Sequential()\n",
    "model.add(CuDNNLSTM(200, input_shape=(n_timesteps, 1), return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(1, activation='sigmoid')))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# train LSTM\n",
    "\n",
    "samples = np.random.choice(range(df.shape[0]), 100, replace = False)\n",
    "\n",
    "# generate new random sequence\n",
    "X,y = get_sequence(0, n_timesteps)\n",
    "# fit model for one epoch on this sequence\n",
    "model.fit(X,y, batch_size = 10000, verbose = 1, epochs  = 1000, callbacks=[earlystop])\n",
    "\n",
    "# evaluate LSTM\n",
    "# X,y = get_sequence(n_timesteps, n_timesteps)\n",
    "# yhat = model.predict_classes(X, verbose=0)\n",
    "# for i in range(n_timesteps):\n",
    "#     print('Expected:', y[0, i], 'Predicted', yhat[0, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = np.random.choice(range(df.shape[0]), 2, replace = False)\n",
    "\n",
    "epoch = epoch[1]\n",
    "print(epoch)\n",
    "\n",
    "X,y = get_sequence(epoch, n_timesteps)\n",
    "yhat = model.predict_classes(X, verbose=0)\n",
    "\n",
    "plt.plot(X[0,:,0])\n",
    "plt.plot(yhat[0,:,0]*np.max(X[0,:,0]), c = 'red')\n",
    "plt.plot(y[0,:,0]*np.max(X[0,:,0]), c= 'green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X[0, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X = np.linspace(0.0 , 2.0 * np.pi, 10000).reshape(-1, 1)\n",
    "Y = np.sin(X)\n",
    "\n",
    "x_scaler = MinMaxScaler()\n",
    "#y_scaler = MinMaxScaler(feature_range=(-1.0, 1.0))\n",
    "y_scaler = MinMaxScaler()\n",
    "\n",
    "X = x_scaler.fit_transform(X)\n",
    "Y = y_scaler.fit_transform(Y)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='loss', patience=7, verbose=1, mode='auto')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(400, input_dim=X.shape[1], kernel_initializer='uniform', activation='tanh'))\n",
    "model.add(Dense(400, activation='tanh'))\n",
    "model.add(Dense(400, activation='tanh'))\n",
    "model.add(Dense(400, activation='tanh'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "history= model.fit(X, Y, epochs=500, batch_size=3200, verbose=2)#, callbacks=[earlystop])\n",
    "\n",
    "res = model.predict(X, batch_size=3200)\n",
    "\n",
    "res_rscl = y_scaler.inverse_transform(res)\n",
    "\n",
    "Y_rscl = y_scaler.inverse_transform(Y)\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.plot(res_rscl, label='ann')\n",
    "plt.plot(Y_rscl, label='train')\n",
    "plt.xlabel('#')\n",
    "plt.ylabel('value [arb.]')\n",
    "plt.legend()\n",
    "plt.subplot(212)\n",
    "plt.plot(Y_rscl - res_rscl, label='diff')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "\n",
    "\n",
    "plt.plot(history.history['mean_absolute_error'], c = \"orange\")\n",
    "plt.title('Neural network mean_absolute_error')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], c = \"orange\")\n",
    "plt.title('Neural network loss')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "\n",
    "# Generate dummy data\n",
    "x_train = np.random.random((1000, 20))\n",
    "y_train = np.random.randint(2, size=(1000, 1))\n",
    "x_test = np.random.random((100, 20))\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=16, epochs=10)\n",
    "score = model.evaluate(x_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate sequence\n",
    "ts = np.arange(0, 1000)\n",
    "\n",
    "seq = []\n",
    "for ii in range(len(ts)):\n",
    "    if ii < 5:\n",
    "        seq.append(np.random.randn(1))\n",
    "    else:\n",
    "        seq.append(np.random.randn(1) + 0.8*seq[ii-1]+ 0.2*seq[ii - 2] - 0.0*seq[ii -4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(seq).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kk +=1\n",
    "\n",
    "#seq = np.array(df.iloc[(kk*20000):((kk + 1) * 20000), 1])\n",
    "\n",
    "timesteps = np.linspace(0, 1, num = 200000)\n",
    "freq = ((np.sin(timesteps*timesteps/2*10*2*np.pi) + 1)**3 > 4 ) + 0.3\n",
    "seq = np.sin((freq*100 * timesteps) * 2 * np.pi)\n",
    "plt.plot(timesteps, seq)\n",
    "plt.plot(timesteps, freq + 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = df.loc[:,\"scaledBuzz\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "\n",
    "f, t, Sxx = signal.spectrogram(np.array(seq), 200000, noverlap = 4000, nperseg = 5000)\n",
    "Sxx = Sxx[0:10]\n",
    "f = f[0:10]\n",
    "plt.pcolormesh(t, f, Sxx)\n",
    "plt.ylim(0,500)\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#buzzes = freq > 1.0\n",
    "buzzes = df.buzz\n",
    "plt.plot(buzzes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale dataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(np.array(seq).reshape(-1,1))\n",
    "plt.plot(dataset[0:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "look_back = 300\n",
    "\n",
    "trainX, trainY = create_dataset(dataset[0:150000], look_back)\n",
    "testX, testY = create_dataset(dataset[150001:], look_back)\n",
    "\n",
    "print(trainY.shape)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.shape\n",
    "plt.plot(trainX[:, 0, -1])\n",
    "\n",
    "trainY= buzzes[0:trainX.shape[0]]\n",
    "plt.plot(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testY=buzzes[trainX.shape[0]:(trainX.shape[0] + testY.shape[0])]\n",
    "plt.plot(testX[:,0,-1])\n",
    "plt.plot(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import CuDNNLSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "earlystop = EarlyStopping(monitor='loss', patience=10, verbose=1, mode='auto', min_delta = 0.001)\n",
    "\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(CuDNNLSTM(4, input_shape=(1, look_back), return_sequences = False))\n",
    "#model.add(Dense(4, input_shape=(1, trainX.shape[2] )))\n",
    "model.add((Dense(1, activation = \"sigmoid\")))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "hitory = model.fit(trainX, trainY, epochs=4000, batch_size=30000, verbose=1, callbacks = [earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hitory.history.keys())\n",
    "\n",
    "\n",
    "plt.plot(hitory.history['loss'], c = \"orange\")\n",
    "plt.title('Neural network loss')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forwardSteps = 5000\n",
    "\n",
    "for ii in range(forwardSteps):\n",
    "    if(ii == 0): \n",
    "        Xtest = np.zeros((forwardSteps, 1, look_back)) # pre-allocate\n",
    "        Xtest[ii, 0, :] = testX[0:1,:,:]\n",
    "    else:\n",
    "        tmp = model.predict(Xtest[(ii-1):(ii), :,:])      \n",
    "        t2 = np.hstack([Xtest[ii-1, :, :], tmp])\n",
    "        t3 = np.delete(t2, 0)\n",
    "        t4 = t3.reshape(1,1,look_back)\n",
    "        #Xtest = np.concatenate([Xtest, t4], axis = 0)\n",
    "        Xtest[ii, 0, :] = t4\n",
    "        \n",
    "    if(np.mod(ii, 300) == 0):\n",
    "        print(ii)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = trainY.reshape(-1)\n",
    "testY = testY.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "trainPredict = model.predict_classes(trainX)\n",
    "testPredict = model.predict_classes(Xtest)\n",
    "# invert predictions\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY_s = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY_s = scaler.inverse_transform([testY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "plt.plot(trainY_s[0,:])\n",
    "plt.plot(trainPredict, c=\"orange\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(testY_s[0,:])\n",
    "plt.plot(testPredict, c= 'orange')\n",
    "#plt.xlim(0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = trainY.reshape(-1)\n",
    "testY = testY.reshape(-1)\n",
    "\n",
    "# make predictions\n",
    "trainPredict = model.predict_classes(trainX)\n",
    "testPredict = model.predict_classes(testX)\n",
    "# invert predictions\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "# plot\n",
    "plt.plot(trainY[0,:])\n",
    "plt.plot(trainPredict, c=\"orange\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(testY[0,:])\n",
    "plt.plot(testPredict[1:], c= 'orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
